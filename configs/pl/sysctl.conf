#
# /etc/sysctl.conf
#
# Zobacz także:
# http://manpages.ubuntu.com/manpages/trusty/pl/man5/proc.5.html
# http://manpages.ubuntu.com/manpages/trusty/pl/man7/ip.7.html
# http://manpages.ubuntu.com/manpages/trusty/pl/man7/arp.7.html
# http://manpages.ubuntu.com/manpages/trusty/en/man7/tcp.7.html
#
# Autor: Morfik (morfikov[at]gmail[dot]com)
# Ostatnia aktualizacja: 2015.04.19
# Postęp: 149/655
#

# Określa maksymalny numer jaki może zostać przypisany procesowi. Maksymalna wartość dla 
# systemu 32bit to 32,768, zaś dla systemu 64bit to 4,194,304 (2^22).
kernel.pid_max = 131072

# Określa limit dla liczby procesów w systemie -- wątki (threads) są w istocie procesami, 
# które dzielą przestrzeń adresową.
kernel.threads-max = 16384

# Księgowanie procesów (process accounting) pozwala na szczegółowe monitorowanie pracy systemu. 
# Jądro operacyjne, dzięki temu mechanizmowi, jest w stanie zbierać informacje na temat nazwy 
# procesu, jego właściciela, grupy czy też czasu stworzenia i usunięcia takiego procesu. 
# Dodatkowo są zbierane informacje na temat wykorzystywanych zasobów, takie jak: czas na 
# operacje, zużycie pamięci oraz ilość danych wej/wyj, które proces przesłał. Te dane są 
# zapisywane do pliku w katalogu /var/log/account/ i czytane podczas inicjalizacji księgowania. By
# skorzystać z tego ficzera trzeba mieć kernela z włączoną opcją CONFIG_BSD_PROCESS_ACCT oraz 
# posiadać zainstalowany pakiet "acct". 
#
# Środkowa liczba oznacza procent wolnego miejsca w systemie plików (tam gdzie jest /var/log/), 
# poniżej którego księgowanie zostanie wstrzymane. Jeżeli ilość wolnego miejsca wzrośnie 
# powyżej procentu wyrażonego pierwszą liczbą, księgowanie zostanie wznowione. Ostatnia liczba 
# oznacza częstość sprawdzania wolnego miejsca i wyrażona jest w sekundach.
kernel.acct = 4 2 60

# Syslog zawiera dość newralgiczne informacje, które mogą zostać użyte przy exploitowaniu
# innych podatności. Gdy parametr zostanie ustawiony na "0", każdy użytkownik będzie mógł
# odczytywać logi via dmesg lub inne podobne mechanizmy. W przypadku ustawienia "1", tylko
# użytkownicy posiadający CAP_SYSLOG (CAP_SYS_ADMIN) będą mogli to robić. Domyślnie takie
# uprawnienia ma tylko root. 
# -- http://lwn.net/Articles/414813/
kernel.dmesg_restrict = 1

# Ukrycie symbolów jądra wraz z ich adresami w pliku /proc/kallsyms (zostaną zastąpione zerami) 
# przed normalnymi użytkownikami (pomijając tych, którzy mają przyznanego CAP_SYSLOG). Utrudnia 
# to trochę exploitom wykorzystywanie podatności jądra na dynamiczne odnajdywanie symboli / 
# adresów pamięci, zwłaszcza gdy kompilujemy własny kernel.  Przy wartości "2" symbole jądra 
# zostaną zawsze zastąpione zerami, niezależnie od posiadanych przywilejów.
# -- https://lwn.net/Articles/415603/
kernel.kptr_restrict = 1

# Zrzut pamięci (coredump) jest to skopiowanie pamięci roboczej jakiejś aplikacji na bardziej
# wiarygodne medium (dysk twardy), w chwili gdy dochodzi do jakiegoś zdarzenia, np. poważnego
# błędu aplikacji. Nazwy, pod jakimi zachowywany jest plik, można zmienić, tak samo jak i
# lokalizację do zapisu tych plików. Obecną konfigurację można przetestować przez wydanie
# poniższych poleceń: 
#
#	$ ulimit -c unlimited
#	$ kill -s SIGSEGV $$
#
# Doprowadzą one do segmentation fault shella, w którym zostaną wydane, a sam zrzut będzie
# zapisany w aktualnej lokalizacji powłoki, w której się użytkownik znajdował przed
# wystąpieniem błędu. Domyślną nazwą dla pliku ze zrzutem pamięci jest "core". Przez
# ustawienie poniższego parametru na wartość "1", nazwa pliku ulegnie zmianie na "core.PID".
# Jeśli core_pattern nie zawiera "%p" oraz core_uses_pid jest ustawiony na "1", wtedy ".PID"
# zostanie dołączony do nazwy pliku. Przydatne przy debugowaniu wielowątkowych aplikacji.
kernel.core_uses_pid = 0
#
# Poniższy parametr jest używany do sprecyzowania wzoru nazwy dla pliku zawierającego zrzut
# pamięci. Maksymalna ilość znaków to 128, domyślna wartość to "core". Poniżej są
# rozpisane parametry, które można wykorzystać przy tworzeniu nazwy dla pliku:
#
#	%% - pojedynczy znak %
#	%p - Identyfikator (PID) procesu, który zrzucił pamięć
#	%u - (numeryczny) identyfikator użytkownika (UID) procesu, który zrzucił pamięć
#	%g - (numeryczny) identyfikator grupy (GID) procesu, który zrzucił pamięć
#	%s - numer sygnału powodującego zrzut pamięci
#	%t - czas zrzutu wyrażony  w sekundach od początku epoki, czyli od 1970-01-01 00:00:00 +0000
#        (UTC) 
#	%h - nazwa komputera (taka sama jak nodename zwracane przez uname(2))
#	%e - nazwa pliku wykonywalnego (niepoprzedzona pełną ścieżką do tego pliku)
#	%E - nazwa ścieżki pliku wykonywalnego, z ukośnikami ("/") zastąpionymi przez wykrzykniki
#        ("!") 
#	%c - miękki limit zasobu rozmiaru pliku zrzutu pamięci procesu zrzucającego pamięć (od
#        Linuxa 2.6.24) 
#
# Można również sprecyzować miejsce zapisu pliku przez rozpoczęcie nazwy od "/". Jeśli
# pierwszym znakiem we wzorze jest symbol potoku "|", to wszystko, co po nim  występuje, jest
# traktowane jako program do uruchomienia. Zrzut pamięci w takim przypadku nie jest zapisywany na
# dysku tylko jest przekazywany na standardowe wejście programu.
kernel.core_pattern = /tmp/core.%t.%h.%e.%p
#
# W przypadku aplikacji z ustawionym bitem setuid, zrzut pamięci w chwili błędu takiego programu
# może zawierać poufne informacje, co stanowi zagrożenie dla bezpieczeństwa systemu, bo bit
# setuid na pliku wykonywalnym umożliwia uruchomienie danego programu przez innych użytkowników
# systemu z prawami właściciela tego pliku -- jeśli bit setuid jest ustawiony na programie,
# którego właścicielem jest root, nie ważne kto go wykona, ten program będzie się zachowywał
# tak jakby go uruchomił root. Jeśli ten parametr przyjmie wartość "0", to w przypadku gdy
# dojdzie do jakiejkolwiek zmiany uprawnień podczas startowania aplikacji, nie będzie można
# wykonać zrzutu pamięci. W przypadku "1", wszelkie kwestie bezpieczeństwa są odstawione na
# boczny tor -- ta wartość ma służyć tylko do debugowania. Można także sprecyzować
# wartość "2", która odpowiada za zrzut pamięci binarek, który normalnie by nie miał miejsca
# ale jeśli core_pattern będzie ścieżką absolutną (zaczynającą się znakiem "/") lub
# potokiem, to zrzut zostanie dokonany. 
fs.suid_dumpable = 0

# Poniższy parametr definiuje zachowanie klawisza SysRq (alt+print_scr+polecenie). Można tutaj
# sprecyzować następujące wartości:
#
#      0 - całkowicie wyłącza sysrq
#      1 - włącza wszystkie funkcje sysrq
#
# Wartości większe od "1" to maska bitowa dozwolonych funkcji sysrq, jak poniżej:
#
#      2 - włącza kontrolę poziomu logów konsoli *
#      4 - włącza kontrolę klawiatury (SAK, unraw) *
#      8 - włącza zrzuty procesów w celu debugowania itd.
#     16 - włącza polecenie sync *
#     32 - włącza ponowne montowanie tylko do odczytu *
#     64 - włącza sygnały procesów (term, kill, oom-kill)
#    128 - pozwala na restartowanie/wyłączanie *
#    256 - pozwala ustawiać nice wszystkich zadań czasu rzeczywistego *
#
# Domyślnie ustawione na 438 (2+4+16+32+128+256).
# -- https://www.kernel.org/doc/Documentation/sysrq.txt
kernel.sysrq = 438

# Poniższy parametr definiuje sposób w jaki zachowa się system po wciśnięciu kombinacji
# ctrl+alt+delete . W przypadku ustawienia "0", sygnał jest przesyłany do programu init, co
# pozwala na zwyczajne zamknięcie systemu i niczym się to nie różni od skorzystania z polecenia
# shutdown . Jeśli się tutaj ustawi "1", system zostanie zresetowany tak jakby to się odbyło
# przez przycisk na obudowie. 
kernel.ctrl-alt-del = 0

# Poniższe parametry ustawiają domenę i nazwę hosta. Mają dokładnie taki sam efekt co w
# przypadku skorzystania z narzędzi hostname i domainname .
kernel.hostname = morfikownia
kernel.domainname = mhouse.lh

# Określają rodzaj systemu operacyjnego oraz numerek kernela. Dodatkowo "#1" w parametrze version
# oznacza, że jest to pierwszy kernel zbudowany z tego źródła, a data na końcu wskazuje kiedy
# ów kernel został zbudowany. (wartości tylko do odczytu)
#kernel.ostype = Linux
#kernel.osrelease = 3.14-1-amd64
#kernel.version = #1 SMP Debian 3.14.4-1 (2014-05-13)

# W przypadku kompilowania np. kernela (via make -j), inne procesy mogą cierpieć z powodu niezbyt
# dobrego dostępu do rdzeni procesora, np. film może się przycinać w czasie kompilacji. Ten
# efekt może być zaobserwowany, w chwili gdy kompilacja jest przeprowadzana w jednym oknie
# terminala, a np. smplayer jest odpalany już w drugim oknie. Dla przeciętnego zjadacza chleba,
# który nie korzysta z żarłocznych aplikacji startowanych w wielu terminalach wykorzystujących
# przy tym wiele wątków, ustawienie tej opcji na 1 nie przyniesie praktycznie żadnego efektu.
# -- http://marc.info/?l=linux-kernel&m=128993935321081&w=2
kernel.sched_autogroup_enabled = 1

# W przypadku pewnych sytuacji, kernel napotyka problem, który jest na tyle poważny, że może
# zachwiać dalszym funkcjonowaniem maszyny. W takich przypadkach kernel zwyczajnie przestaje
# odpowiadać, a cała sytuacja jest znana bardziej jako kernel panic. Poniższy parametr określa
# ilość czasu (w sekundach), po którym system zostanie uruchomiony ponownie w przypadku paniki
# kernela. Jeśli ten parametr zostanie ustawiony na "0", reboot zostanie wyłączony.
kernel.panic = 60
#
# Mniej poważne błędy kernela są nazywane "oops". Nie doprowadzają one bezpośrednio do paniki
# kernela, gdyż ten może się obronić ubijając złowrogi proces. W sporej części przypadków
# "oops", system z mniejszym lub większym powodzeniem może pracować dalej. Poniższa opcja,
# jeśli ustawiona na "0", sprawi, że kernel będzie próbował funkcjonować dalej. Jeśli zaś
# zostanie ustawiona na "1", kernel spanikuje natychmiast. Dodatkowo, jeśli parametr panic jest
# ustawiony na niezerową wartość, system zostanie zresetowany. 
kernel.panic_on_oops = 0

# Każda niezerowa wartość wskazuje na fakt, że kernel ma załadowane moduły, które nie są do
# końca free, prawdopodobnie sterowniki do grafik lub bezprzewodowych kart sieciowych. Deweloperzy
# kernela nie są zbytnio zainteresowani problemami występującymi w takich jądrach, bo nie mogą
# ustalić przyczyny, której nie można dostrzec z racji, że takie moduły posiadają zamknięty
# kod. Poniżej znajduje się lista wartości, które mogą być dodane do siebie, dając tym samym
# wynikową wartość: 
#
#      1 - A module with a non-GPL license has been loaded, this includes modules with no license.
#          Set by modutils >= 2.4.9 and module-init-tools.
#      2 - A module was force loaded by insmod -f. Set by modutils >= 2.4.9 and module-init-tools.
#      4 - Unsafe SMP processors: SMP with CPUs not designed for SMP.
#      8 - A module was forcibly unloaded from the system by rmmod -f.
#     16 - A hardware machine check error occurred on the system.
#     32 - A bad page was discovered on the system.
#     64 - The user has asked that the system be marked "tainted".  This could be because they are
#          running software that directly modifies the hardware, or for other reasons.
#    128 - The system has died.
#    256 - The ACPI DSDT has been overridden with one supplied by the user instead of using the one
#          provided by the hardware.
#    512 - A kernel warning has occurred.
#   1024 - A module from drivers/staging was loaded.
#   2048 - The system is working around a severe firmware bug.
#   4096 - An out-of-tree module has been loaded.
#   8192 - An unsigned module has been loaded in a kernel supporting module signature.
#
# Dla przykładu wartość "4097" to suma "4096" i "1", czyli załadowany jest moduł na licencji
# nie GPL. W logu kernela można zwykle odszukać informacje wskazujące na moduły, które plamią
# opensourcowe imię kernela: 
#
#    # dmesg | grep -i taint
#    [Tue Jun 10 06:19:38 2014] nvidia: module license 'NVIDIA' taints kernel.
#    [Tue Jun 10 06:19:38 2014] Disabling lock debugging due to kernel taint
#
# W tym przypadku winne są sterowniki nvidii. Po ich usunięciu poniższy parametr powinien
# wskazywać wartość "0".
#kernel.tainted = 4097

# Pamięć współdzielona (shared memory) jest to taki obszar pamięci, który może być dzielony
# przez kilka różnych procesów w celu wymiany informacji między tymi procesami. Takie
# rozwiązanie jest szybsze od standardowej międzyprocesowej komunikacji (Inter Process
# Communication), bo w przypadku gdy pamięć jest mapowana na przestrzeń adresową procesu,
# który współdzieli dany obszar pamięci, kernel nie bierze udziału w przekazywaniu danych
# między procesami, bo nie ma potrzeby by te dane kopiować. Wiele aplikacji korzysta z tego
# ficzeru, np. oprogramowanie od baz danych. By ustalić jakie limity są w systemie, można
# skorzystać z "ipcs -lm", przykładowo:
#
#    $ ipcs -lm
#    ------ Shared Memory Limits --------
#    max number of segments = 4096                       - shmmni
#    max seg size (kbytes) = 65536                       - shmmax
#    max total shared memory (kbytes) = 524288           - shmall
#    min seg size (bytes) = 1                            - minimalny rozmiar segmentu do
#                                                          współdzielenia 
#
# Poniższy parametr kontroluje całkowitą ilość pamięci współdzielnej, która może być
# wykorzystana w tym samym czasie na danym systemie. Ten parametr nie jest definiowany w bajtach,
# tylko w stronach (page) i by uzyskać maksymalną ilość pamięci przeznaczoną do
# współdzielenia, trzeba pomnożyć wartość tego parametru przez rozmiar strony, zwykle 4096 bajtów.
kernel.shmall = 131072
#
# Definiuje maksymalny rozmiar dla pojedynczego segmentu współdzielonego (w bajtach).
kernel.shmmax = 67108864
#
# Ten parametr jest używany do ustawienia maksymalnej ilości współdzielonych segmentów w systemie. 
kernel.shmmni = 4096
#
# W przypadku ustawienia shmall na "0", czyli usunięcia górnego limitu dla pamięci
# współdzielonej, istnieje możliwość, że użytkownik systemu będzie w stanie wykorzystać
# całą dostępną pamięć na segmenty SHM. Jeśli tego typu sytuacja wystąpi, OOM-killer nie
# będzie w stanie uwolnić tych zasobów pamięci. Jednym z dwóch rozwiązań jest włączenie
# opcji shm_rmid_forced , która wymusza aby każdy segment SHM był tworzony z flagą IPC_RMID ,
# która to gwarantuje, że dany segment SHM jest przypisany do co najmniej jednego procesu, co z
# kolei zapewnia, że w przypadku wyczerpania się pamięci, OOM-killer zdoła ubić winny proces,
# a segment SHM zniknie razem z tym procesem. Drugą opcją jest ustawienie górnego limitu dla
# pamięci współdzielonej w parametrze shmall .
# -- http://lwn.net/Articles/595638/
#
# Jeśli poniższy parametr zostanie ustawiony na "1", wszystkie segmenty zostaną przeznaczone do
# usunięcia, w momencie gdy liczba dołączonych do nich procesów spadnie do 0 i co z tym się
# wiąże, nie da się utworzyć współdzielonych segmentów pamięci istniejących niezależnie
# od procesów. Tego typu zachowanie może popsuć pewne aplikacje.
kernel.shm_rmid_forced = 0

# Pierwszy parametr zawiera ścieżkę do programu ładującego moduły jądra, drugi zaś
# umożliwia dynamiczne ładowanie i wyładowywanie modułów. Oba parametry są dostępne tylko w
# przypadku gdy kernel został skompilowany z opcją CONFIG_MODULES . W przypadku ustawienia
# modules_disabled na "1", nie da rady przestawić ten opcji z powrotem na "0".
kernel.modprobe = /sbin/modprobe
#kernel.modules_disabled = 0

# Poniższy parametr ustawia próg limitu dla liczby pseudoterminali (tych odpalanych w graficznym
# środowisku). 
kernel.pty.max = 4096
#
# Wartość tylko do odczytu przechowująca informacje na temat liczby aktualnie otworzonych
# pseudoterminali. 
#kernel.pty.nr = 6

# Kernel generuje logi z wykorzystaniem printk(). Te logi są zapisywane w buforze, do którego to
# można się odwołać przez dmesg. Z kolei rozmiar tego bufora jest kontrolowany przez opcję
# kernela CONFIG_LOG_BUF_SHIFT , której argumentem jest liczba, np. 17 -- oznacza ona rozmiar
# bufora 128KiB (2^17). Rozmiar pojedynczej wiadomości nie może przekraczać 1KiB. W zależności
# od ważności komunikatu, te dzielimy na: 
#
#   0 KERN_EMERG
#   1 KERN_ALERT
#   2 KERN_CRIT
#   3 KERN_ERR
#   4 KERN_WARNING
#   5 KERN_NOTICE
#   6 KERN_INFO
#   7 KERN_DEBUG
#
# Poniższe cztery wartości odpowiadają za console_loglevel, default_message_loglevel,
# minimum_console_level oraz default_console_loglevel . Komunikaty o priorytecie wyższym (niższy
# numer) niż console_loglevel będą wypisywane na konsoli. Komunikaty bez jawnego priorytetu,
# będą wypisywane z priorytetem ustawionym w default_message_level. Z kolei
# minimum_console_loglevel jest najmniejszą wartością, którą można ustawić w console_loglevel,
# a default_console_loglevel jest domyślną wartością dla console_loglevel.  
kernel.printk = 1 4 1 7
#
# Precyzuje opóźnienie kolejnych komunikatów (czas w milisekundach). Dozwolone wartości z
# zakresu od 0 do 10000.
kernel.printk_delay = 0
#
# Pierwszy parametr definiuje limit wiadomości, po przekroczeniu którego kernel zaprzestanie
# wypisywać komunikaty przez pewien okres czasu, który zostanie sprecyzowany w printk_ratelimit .
# Ten mechanizm ma zastosowanie jedynie w przypadku wykrycia takich samych wiadomości.
# -- http://lwn.net/Articles/66091/
kernel.printk_ratelimit_burst = 10
kernel.printk_ratelimit = 5

# Wartość tego parametru (tylko do odczytu) pokazuje jak dużo entropii maszyna zgromadziła -- jeśli
# jest niska (<1000), kryptograficzne aplikacje mogą się blokować do chwili gdy napłynie
# więcej entropii, co może np. spowolnić działanie sieci bezprzewodowych, w przypadku gdy
# serwer robi za programowy access point. By zwiększyć ilość i jakoś entropii, można
# posłużyć się demonami entropii np. haveged lub rngd z pakietu rng-tools . Ten drugi operuje
# na sprzętowym generatorze (urządzenie /dev/hwrng ). Daemon haveged generuje, co prawda,
# niewyczerpane ilości entropii ale nie jest do końca jeszcze sprawdzony i najlepiej nie polegać
# tylko na nim, ewentualnie używać go w połączeniu z rngd . 
# -- http://lwn.net/Articles/525459/
#kernel.random.entropy_avail = 2730
#
# Ustawiony na sztywno limit dla puli entropii (wartość tylko do odczytu).
#kernel.random.poolsize = 4096
#
# W przypadku gdy licznik entropy_avail spadnie do 0, proces, który żąda entropii z pliku
# /dev/random zostanie uśpiony do momentu aż entropy_avail pokaże wartość ustawioną w tym
# parametrze. 
kernel.random.read_wakeup_threshold = 128
#
# Próg, powyżej którego urządzenie /dev/random zostanie odcięte od dokarmiania nowymi porcjami
# entropii.  
kernel.random.write_wakeup_threshold = 2048
#
# Wartość tylko do odczytu, generowana za każdym razem gdy jakiś proces spróbuje odczytać ten
# parametr. Ciąg ma formę xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx , gdzie za "x" można podstawić
# dowolną wartość hexalną, a "y" może przyjąć wartości ze zbioru 8,9,A,B. Wartość tego
# parametru jest przypisywana np. partycjom przy tworzeniu nowego systemu plików.
#kernel.random.uuid = bad69d77-d1cc-465c-b5e1-ecd8519e179e
#
# Wartość tylko do odczytu, która jest generowana podczas startu systemu. Przydatne, jeśli
# ktoś chce wiedzieć czy system został zresetowany.
#kernel.random.boot_id = 55e71850-b022-528e-898d-8c7528883822

# Fizyczna pamięć jest podzielona na strony (pages), które są podstawową jednostką zarządzania
# pamięcią. Kiedy proces uzyskuje dostęp do wirtualnego adresu, procesor musi przetłumaczyć go
# na adres fizyczny, a robi to w oparciu o tablicę stron, którą dostarcza kernel. Zanim jednak
# procesor może dokonać takiego tłumaczenia, musi on przeprowadzić szereg odczytów pamięci
# fizycznej i uzyskać informację o tej tablicy. By przyśpieszyć ten proces dla późniejszych
# odwołań do tego samego adresu wirtualnego, procesor zapisuje informacje na temat ostatnio
# odwiedzonych adresów w TLB (Translation Lookaside Buffer). TLB jest to mały ale bardzo szybki
# cache CPU i nietrafianie przy odpytywaniu adresów kosztuje sporo czasu. Jednak można
# zwiększyć liczbę trafień przez zmapowanie większych ciągłych obszarów pamięci fizycznej
# przez zwiększenie rozmiaru strony, który domyślnie wynosi 4KiB. Im większe są strony, tym
# mniej wpisów zawiera tablica, a im mniej wpisów, tym lepsze i szybsze jest zarządzanie
# pamięcią, bo mniej czasu zajmuje odnalezienie zmapowanego obszaru. 
#
# Mechanizm, zwany HugePages, pozwala zwiększyć, w zależności od procesora, rozmiar strony do 2MiB
# lub nawet do 1GiB. Jednak HugePages znajdują zastosowanie tylko w przypadku pamięci
# współdzielonej i jeśli zostanie przeznaczony jakiś obszar pamięci pod HugePages, będzie on
# prealokowany i nigdy nie zostanie przeniesiony do SWAP. Aplikacje, które używają tylko
# zwykłych stron, nie będą mogły się odwoływać do tego zarezerwowanego miejsca w pamięci.
# Wielkość strony można odczytać z /proc/meminfo lub też przez sprawdzenie flag procesora w
# /proc/cpuinfo -- PSE dla 2MiB i PDPE1GB dla 1GiB. Trzeba także posiadać kernel z włączonymi
# opcjami CONFIG_HUGETLBFS , CONFIG_HUGETLB_PAGE .
#
# Wartość tego parametru określa ilość HugePages w systemie.
#vm.nr_hugepages = 200
#
# Poniższy parametr precyzuje jak bardzo może się rozrosnąć przestrzeń pamięci pod HugePages, w
# przypadku gdy jakiś proces potrzebuje zaalokować więcej pamięci ale limit w nr_hugepages
# został przekroczony. W przypadku gdy ten proces straci apetyt na pamięć, te strony zostaną
# zwolnione. 
#vm.nr_overcommit_hugepages = 50
#
# Wartość tego parametru ustala grupę, w skład której wchodzą użytkownicy mogący korzystać
# z ficzeru HugePages. Grupę pierw trzeba stworzyć i następnie dodać do niej określonych
# użytkowników. Trzeba także utworzyć punkt montowania oraz dodać wpis do /etc/fstab w postaci:
#
#	hugetlbfs /hugepages hugetlbfs mode=1770,gid=5555 0 0
#
#vm.hugetlb_shm_group = 5555

# Swappiness określa tendencje do zrzucania nieużywanych (z punktu widzenia kernela) danych z
# pamięci na dysk. Im ten parametr jest wyższy (max 100), tym kernel chętniej to robi, co może
# czasem niebyt pozytywnie się odbić na wydajności systemu. Ustawienie zbyt niskiej wartości
# może doprowadzić do przywieszania się systemu w chwili wyczerpywania się dostępnej ilości
# pamięci operacyjnej. W przypadku ustawienia "0", kernel będzie przenosił dane do SWAP tylko w
# sytuacjach OOM (Out Of Memory). 
# -- http://lwn.net/Articles/100978/
vm.swappiness = 30

# Kontroluje liczbę stron, które mogą być jednocześnie odczytane ze SWAP. W przypadku gdy SWAP
# jest dość intensywnie wykorzystywany, zwiększenie wartości tego parametru może polepszyć
# wydajność. 
# 
#   wartość | ilość stron |  rozmiar (bajty)
#  ---------+-------------+-------------------
#      0    |       1     | 1*4096  =4096
#      1    |       2     | 2*4096  =8192
#      2    |       4     | 4*4096  =16384
#      3    |       8     | 8*4096  =32768
#      4    |      16     | 16*4096 =65536
#      5    |      32     | 32*4096 =131072
#     ...   |     ....    |       ...
#
# Wartość "10" pozwala na odczyt 4MiB danych.
vm.page-cluster = 10

# System plików jest reprezentowany w pamięci za pomocą inodów (inode) oraz dentrów (dentry):
#
#	/
#	|
#	foo
#	|   \
#	bar  bar2
#
# Inody reprezentują podległe im pliki lub katalogi, zaś dentry są to obiekty składające się
# z nazwy, linku do inode oraz linku do katalogu nadrzędnego, innymi słowy, jest to struktura
# drzewa katalogów. Na powyższym obrazku widnieją 4 inody, odpowiedzialne za foo, bar, bar2 oraz
# root. Są tam także 3 dentry linkujące bar z foo, bar2 z foo oraz foo z root, np. denter bar ma
# nazwę bar, linkuje do pliku bar (inode) oraz linkuje do katalogu nadrzędnego foo.
# http://www.fieldses.org/~bfields/kernel/vfs.txt
#
# Przy przeglądaniu struktury plików i katalogów, dane na jej temat są cachowane w pamięci RAM.
# Przy sporej ilości operacji dyskowych, ten cache pod inody i dentry może zając sporo miejsca.
# Domyślnie poniższy parametr jest ustawiony na 100. Jeśli zostanie zmniejszony, kernel będzie
# chciał zachować te dane w pamięci RAM dłużej. W przypadku ustawienia tego parametru na 0,
# nigdy ich nie usunie, co może zakończyć się OOM. Z kolei zwiększenie wartości (> 100)
# sprawi, że kernel będzie się upominał o pamięć, którą zajmują inody i denty w przypadku
# sporego obciążenia maszyny. 
vm.vfs_cache_pressure = 50

# Minimalna ilość pamięci RAM, która musi pozostać w formie nieużywanej. Ustawienie byt niskiej
# wartości może uniemożliwić systemowi odzyskiwanie pamięci, co może doprowadzić do przycinania
# się systemu i ubijania wielu procesów przez OOM-killera. Z kolei ustawienie zbyt dużej wartości
# (5-10% całkowitej pamięci) doprowadzi do natychmiastowego wyczerpania się pamięci, gdyż
# system będzie spędzał zbyt wiele czasu na odzyskiwaniu pamięci, bo linux jest tak
# zaprojektowany by używał całej dostępnej przestrzeni w pamięci RAM pod cahowanie plików.
# Ten parametr domyślnie jest kalkulowany na starcie systemu w oparciu o ilość dostępnej pamięci
#  RAM. 
vm.min_free_kbytes = 8192

# Ta opcja włącza zabijanie procesów w sytuacjach OOM. W przypadku ustawienia tego parametru na
# "0", kernel przeskanuje procesy i ubije ten co zjada najwięcej zasobów pamięci RAM. Gdy
# zostanie ustawiona wartość "1", kernel ubije tę aplikację, która doprowadziła do stanu OOM,
# przy czym niekoniecznie musi to był nowo uruchomiony program, co może doprowadzić do zabijania
# pożytecznych procesów, które wcale nie zagrażają systemowi. W przypadku posiadania partycji
# SWAP, dane będą tam zrzucane i żaden proces nie zostanie zabity do momentu zapełnienia się SWAP.
# -- http://lwn.net/Articles/317814/ 
vm.oom_kill_allocating_task = 0
#
# Włącza zrzut wszystkich zadań w systemie za wyjątkiem wątków kernela w chwili gdy kernel
# dokonuje zabijania żarłocznych procesów (OOM-killing). Zrzut  zawiera następujące informacje
# o każdym zadaniu (wątku, procesie): identyfikator wątku (pid), realny identyfikator
# użytkownika (uid), identyfikator grupy wątku (gid), rozmiar pamięci wirtualnej (vm size),
# rozmiar zestawu rezydentnego (rss), procesor któremu przydzielono zadanie (nr_ptes), wynik
# oom_adj (/proc/<pid>/oom_adj , /proc/<pid>/oom_score , /proc/<pid>/oom_score_adj) i nazwę
# polecenia (name). Jest to pomocne w celu zidentyfikowania procesu, który zainicjował OOM-killera.
# Dodatkowo zostanie wypisanie info dlaczego OOM-killer wybrał akurat to zadanie do zabicia.
# Ustawienie tej wartości na "0" spowoduje, że ta informacja nie zostanie wyświetlona. W przypadku
# wielkich systemów z tysiącami procesów, tego typu zrzut  może okazać się niezbyt dobrym pomysłem. 
vm.oom_dump_tasks = 1
#
# W przypadku ustawienia "1", kernel spanikuje za każdym razem gdy dojdzie do sytuacji OOM. W
# przypadku gdy proces limituje nody przez mempolicy/cpusets i te nody zaczną wyczerpywać
# pamięć RAM, sam proces może zostać zabity przez OOM-killera. W takim przypadku kernel nie
# spanikuje, bo nody pamięci zostaną uwolnione. Gdy ten parametr zostanie ustawiony na "2",
# kernel spanikuje w każdej sytuacji. 
vm.panic_on_oom = 0

# PageCache/BufferCache przyspiesza odczyt plików przez buforowanie danych w pamięci RAM przy
# pierwszym odczycie lub zapisie plików na dysku. Jeśli zajdzie potrzeba by w późniejszym
# czasie odczytać te dane ponownie, to system odwoła się do pamięci RAM zamiast do dysku
# twardego, co przyśpieszy znacznie operacje na plikach. W przypadku gdyby system potrzebował
# więcej pamięci pod aplikacje, zwolni on część obszaru wykorzystywanego w danej chwili przez
# PageCache.
#
# W zależności od sprecyzowanej wartości, część cache w pamięci RAM zostanie wyczyszczona. W
# przypadku przesłania "1", kernel uwolni cały PageCache, w przypadku "2", cache pod inody i
# dentry zostanie zwolniony. Można także przesłać "3", co spowoduje uwolnienie tych dwóch
# powyżej. Jednak dirty pages nie zostaną w ten sposób wyczyszczone. Jeśli istnieje potrzeba
# wyczyszczenia całego cache, trzeba pierw wydać polecenie sync , po czym przesłać "3" via:
#
#	# echo "3" > /proc/sys/vm/drop_caches
#
# Przy czym ta operacja nie ma trwałego efektu, tj. po wydaniu powyższego polecenia, cache i tak
# będzie się zbierał i by go zwolnić, ponownie trzeba zapisać drop_caches .
#vm.drop_caches = 0

# Dirty pages to dane, które przed zapisaniem na dysk oczekują pewien czas w cache pamięci RAM.
# Im jest ich więcej tym gorsze skutki niesie za sobą pad systemu -- więcej plików zostanie
# uszkodzonych. Dodatkowo za sprawą dirty pages może dochodzić do przerzucania właściwych
# danych z RAM do SWAP podczas kopiowania plików. 
# -- http://lwn.net/Articles/572911/
#
# Maksymalny rozmiar cache pod dirty pages dla pojedynczego procesu (bajty lub %). Zbyt wysokie
# wartości mogą doprowadzić do tworzenia miejsca pod cache w pamięci RAM, co skutkuje
# przerzuceniem innych danych do SWAP. Z kolei zbyt niskie wartości mogą skutecznie ograniczyć
# transfer dysku.  
#vm.dirty_background_bytes = 16777216
vm.dirty_background_ratio = 3
#
# Podobnie jak wyżej, z tym, że dotyczy wszystkich procesów razem wziętych. Tego limitu dirty
# pages nie mogą przekroczyć. Jeśli ten próg zostanie osiągnięty, wtedy wszystkie procesy są
# synchronizowane i nie będą kontynuowane do chwili aż dane zostaną zapisane na dysk. W
# przypadku sporej ilości pamięci RAM, wysoki procent może się odbić niekorzystnie, bo sporo
# danych będzie musiało być zapisane na dysk, co skutkować będzie przywieszaniem się systemu.
#vm.dirty_bytes = 50331648
vm.dirty_ratio = 5
#
# Czas po jakim dirty pages są oznaczane jako stare (4s).
vm.dirty_expire_centisecs = 400
#
# Częstotliwość z jaką wybudzany jest kernelowski flusher by zapisać stare dirty pages na dysk
# (10s). 
vm.dirty_writeback_centisecs = 1000

# W przypadku gdy opcja jest ustawiona na inną wartość niż "0" i dojdzie do zdarzenia, które
# wybudzi dysk ze stanu uśpienia, wszystkie dirty pages zostaną automatycznie zapisane na dysk w
# czasie określonym w tym  parametrze. Rozsądne wartości od 2s do 5s. Wartość "0" wyłącza
# laptop mode. 
vm.laptop_mode = 5

# Czasami dysk rozkręca talerze z niewiadomego powodu. Kiedy tego typu sytuacja występuje, można
# spróbować ustalić jej przyczynę przy pomocy parametru block_dump . Zanim się jednak uaktywni
# tę opcję, trzeba, albo wyłączyć logi kernela w syslogu, albo wyłączyć sysloga całkowicie.
# W przeciwnym wypadku, system się zapętli, bo informacje o aktywności dysku zbierane będą
# przez syslog, a ten je będzie zapisywał na dysk, a to wygeneruje więcej informacji o aktywności
# dysku i tak dalej. Po wyłączeniu sysloga lub ukryciu logów kernela, by odczytać informacje,
# które zostaną pokazane za sprawą block_dump, trzeba posłużyć się dmesg. 
#
# Przykładowe logi mogą wyglądać jak poniżej:
# bash(273): READ block 3242 on hda1
# bash(273): dirtied inode 10237 (.bash_history) on hda1
# pdflush(6): WRITE block 3242 on hda1
#
# Mówią one, że proces nazwany bash, o numerze ID 273, odczytał blok 3242 na urządzeniu hda1. Ten
# sam proces zmienił plik .bash_history ale dane z tej zmiany nie zostały jeszcze zapisane na
# dysk (figurują w pamięci RAM jako dirty pages). Z kolei proces pdflush zapisał blok 3242 -- dirty
# pages zostały zapisane na dysk. 
# -- http://www.linuxjournal.com/article/7539
vm.block_dump = 0

# Gdy jakiś plik zostaje otwarty, system operacyjny tworzy wpis reprezentujący ten plik i
# przechowujący informacje na jego temat. Jeśli otwartych zostało 100 plików, będzie istnieć 100
# wpisów w kernelu. Te wpisy są określane przy pomocy liczb, np. 100, 101, 102, etc. To są
# deskryptory plików. Ponadto, domyślnie każdy proces po uruchomieniu ma otwarte 3 standardowe
# deskryptory plików: STDIN(0), STDOUT(1), STDERR(2) . To jakie deskryptory ma otwarte jakaś
# aplikacja, można sprawdzić przez: 
#
#	$ ls -al  /proc/$(pidof firefox)/fd/
#
# Deskryptor pliku może odnosić się do pliku, katalogu, urządzenia blokowego lub urządzenia
# znakowego, gniazda, kolejki FIFO, nienazwanego strumienia lub dowiązania symbolicznego. 
#
# Wartość w file-max określa maksymalną liczbę deskryptorów plików w systemie. Gdy tablica się
# zapełni, w logu kernela można znaleźć komunikaty typu: "VFS: file-max limit <number> reached".
# W takim przypadku trzeba zwiększyć wartość tego parametru.
fs.file-max = 100000
#
# Te trzy wartości określają kolejno liczbę zaalokowanych, liczbę zaalokowanych ale nieużywanych
# oraz maksymalną liczbę obecnie otwartych plików w systemie. Przy czym druga liczba, od kernela
# 2.6, zawsze wynosi 0, bo jądro zwalnia nieużywane deskryptory plików. (Wartości tylko do odczytu).
#fs.file-nr = 4384       0       99970
#
# Określa maksymalną liczbę deskryptorów jakie pojedynczy proces może zaalokować.
#fs.nr_open = 1048576

# Każda maszyna posiada pamięć fizyczną, czyli taką, która jest w niej zainstalowana. Dodatkowo
# posiada również przestrzeń adresową, która to jest mapą możliwej do zaadresowania przez proces
# pamięci. Nie cały  jej obszar musi mieć swój odpowiednik w pamięci fizycznej, co jest
# implementowane za pomocą pamięci wirtualnej (SWAP). Dane na temat zaalokowanej pamięci można
# odczytać z /proc/meminfo : 
#
#	$ cat /proc/meminfo | grep -i comm
#	CommitLimit:     2609604 kB
#	Committed_AS:    1404848 kB
#
# -- http://www.win.tue.nl/~aeb/linux/lk/lk-9.html
#
# Gdy ustawione na "0", kernel próbuje ustalić ilość wolnej pamięci w przypadku gdy przestrzeń
# użytkownika prosi o kolejne zasoby. W przypadku ustawienia "1", kernel udaje, że zawsze ma
# wystarczającą ilość pamięci aż do momentu gdy jej faktycznie zabranie. Z kolei wartość "2"
# sprawi, że kernel będzie próbował nie dopuścić do sytuacji, w której możliwe by było zaalokowanie
# więcej zasobów niż faktycznie jest dostępnych. Ta opcja może być bardzo użyteczna, bo wiele
# programów rezerwuje duże ilości pamięci "na wszelki wypadek", a w rzeczywistości z większości
# tych zasobów wcale nie korzysta.
vm.overcommit_memory = 0
#
# W przypadku gdy overcommit_memory jest ustawiony na "2", przestrzeń adresowa do zaalokowana nie
# może przekroczyć sumy wartości dostępnej ilości SWAP oraz procentu pamięci fizycznej ustawionej
# w tym parametrze. Przykładowo, jeśli system posiada do dyspozycji 1GiB pamięci RAM i do tego SWAP
# ma 1GiB, po sprecyzowaniu w overcommit_ratio wartości "50", możliwe będzie do zaalokowanie 1,5GiB.
#vm.overcommit_kbytes = 0
#vm.overcommit_ratio = 100

# MMAP to wywołanie systemowe nakazujące systemowi operacyjnemu odwzorowanie danej części wybranego
# pliku w przestrzeni adresowej procesu. Operacja ta powoduje, że do obszaru pliku można odnosić
# się jak do zwykłej tablicy bajtów w pamięci, eliminując potrzebę korzystania z dodatkowych
# wywołań systemowych typu read lub write. Z tego powodu często używa się tej operacji do
# przyspieszenia działania na dużych plikach. Poniższy parametr określa przestrzeń adresową, której
# procesy użytkownika nie będą mogły mapować. W przypadku gdyby pozwolono na mapowanie niższych
# wartości niż 64KiB, mogą wystąpić problemy z bezpieczeństwem systemu znane jako "kernel NULL
# pointer dereference". Ponieważ kernel w wyniku błędu może operować przez przypadek na informacjach
# zawartych na pierwszych kilku stronach pamięci, to procesom w przestrzeni użytkownika nie powinno
# się zezwalać na ich zapisywanie. Może do doprowadzić do powieszenia się systemu lub niestabilnej
# jego pracy. Dodatkowo, jeśli użytkownik jest w stanie mapować niższe porcje przestrzeni adresowej,
# może także zwiększyć swoje uprawnienia. Część aplikacji do poprawnej pracy wymaga by ustawić tutaj
# "0", jednak pozostałe bez problemu działają przy określeniu wartości "65536".
# -- https://wiki.debian.org/mmap_min_addr
vm.mmap_min_addr = 65536

# Włącza ochronę symbolicznych dowiązań w katalogach z ustawionym sticky bitem, np. w /tmp/ .
# Ustawienie tego bitu chroni przed usuwaniem nieswoich plików w danym katalogu ale pojawia się
# znów problem z eskalacją uprawnień, np. w sytuacji gdy proces posiadający uprawnienia root
# przechodzi przez link symboliczny innego użytkownika. Ustawienie wartości "1" zezwoli na podążanie
# za dowiązaniami tylko w przypadku katalogów bez sticky bitu. W przypadku folderów, które mają
# ustawiony sticky bit, utworzenie symlinku będzie możliwe dopiero wtedy gdy UID dowiązania oraz
# użytkownika przechodzącego będą do siebie pasować, albo właściciel katalogu jest taki sam co w
# przypadku dowiązania. To ustawienie może popsuć część źle napisanych programów ale daje gwarancję,
# że uprawnienia nie zostaną przekroczone za pomocą dowiązań symbolicznych.
fs.protected_symlinks = 1
#
# Ochrona twardych dowiązań działa na podobnej zasadzie co w przypadku dowiązań symbolicznych, z
# tym, że tutaj sytuacja nie ogranicza się tylko do katalogów z ustawionym sticky bitem. W
# przypadków systemów bez oddzielnej partycji na katalog /home/, użytkownik może utworzyć link do
# /etc/shadow w swoim katalogu domowym. W prawdzie właściciel pliku i prawa dostępu są takie same
# jak były ale jakiś proces z prawami roota mógłby przez przypadek zmienić prawa dostępu tego
# dowiązania, np. w wyniku:
#
#   # chown -R morfik:morfik /home/morfik/
#
# Co definitywnie zmieni nie tylko prawa dowiązania ale także prawa do pliku /etc/shadow . Jeśli
# wartość poniższego parametru zostanie ustawiona na "1", tworzenie twardych dowiązań będzie możliwe
# tylko w przypadku plików, do których użytkownik, tworzący owe dowiązanie, posiada prawa zapisu lub
# jest ich właścicielem.
fs.protected_hardlinks = 1

# W przypadku ustawienia na "1", napęd wysunie płytkę od razu po wydaniu polecenia umount -- nie
# trzeba dodatkowo korzystać z eject .
#dev.cdrom.autoeject = 0

# Jeśli ustawione na wartość "1", napęd zamknie tackę po wydaniu polecenia mount i po chwili
# zamontuje płytkę. W przeciwnym wypadku zostanie zwrócony błąd o niemożliwości zamontowania krążka.
#dev.cdrom.autoclose = 1

# Forwardowanie pakietów IPv4 oraz IPv6, wymagane przy udostępnianiu połączenia sieciowego.
net.ipv4.ip_forward = 1
net.ipv6.conf.all.forwarding = 0

# Opcja ta wyłączy odpowiedzi na rozgłaszanie ICMP (ICMP broadcast) co zapobiegnie atakom typu
# smurf. Atak typu smurf polega na wysłaniu wiadomości ICMP typu 0 (czyli ping) na adres całej sieci
# ze sfałszowanego adresu źródłowego, co spowoduje odpowiedź wszystkich działających w tej sieci
# komputerów i zalanie falą pakietów maszyny, której adresu użył atakujący. 
net.ipv4.icmp_echo_ignore_broadcasts = 1

# Wyłączenie odpowiadania na pakiety ping, czyli uczynienie z danej maszyny jednej wielkiej czarnej
# dziury. Bardzo przydatna opcja w przypadku gdy maszyna pracuje w roli klienta. Jeżeli komputer
# robi za serwer, wyłączenie ICMP typu 0 może utrudnić analizowanie źródła problemu np. w wypadku
# awarii serwera. W takim wypadku, dużo lepiej jest odfiltrować pakiety ICMP na zaporze sieciowej. 
net.ipv4.icmp_echo_ignore_all = 0

# Spowolnienie odpowiedzi na pakiety ICMP (2s).
net.ipv4.icmp_ratelimit = 2000
#
# Maska określająca, które bity (żądania ICMP) mają być limitowane:
# 	Bity:  IHGFEDCBA9876543210
#	Maska: 0000001100000011000 (6168)
#		0 Echo Reply
#		3 Destination Unreachable *
#		4 Source Quench *
#		5 Redirect
#		8 Echo Request
#		B Time Exceeded *
#		C Parameter Problem *
#		D Timestamp Request
#		E Timestamp Reply
#		F Info Request
#		G Info Reply
#		H Address Mask Request
#		I Address Mask Reply
#
# Zobacz także include/linux/icmp.h
net.ipv4.icmp_ratemask = 6168

# Niektóre routery wysyłają nieprawidłowe odpowiedzi ICMP na rozgłoszeniowe ramki. Tego typu
# zachowanie stanowi naruszenie RFC 1122 i kernel loguje takie zdarzenia. Te komunikaty można bez
# problemu zignorować. Jednak one będą się pojawiać w dalszym ciągu w logach. Ustawienie poniższego
# parametru na "1" sprawi, że owe komunikaty przestaną być logowane.
net.ipv4.icmp_ignore_bogus_error_responses = 1

# Część z parametrów (/proc/sys/net/ipv4/conf/*/*) jest ustawiana w dość dziwaczny sposób. Chodzi o
# to, że do dyspozycji są co najmniej trzy przełączniki -- default, all oraz nazwa interfejsu, np.
# eth0, a tych może być w systemie kilka i mogą one być dodawane/usuwane dynamicznie. Wszelkie
# domyślne opcje dla nowych interfejsów w systemie są określane przez conf/default/* , z tym, że są
# one ustawiane tylko raz (mogą zostać zmienione w późniejszym czasie). Jeśli chcemy dostosować
# opcje tylko dla określonego interfejsu, np. eth0, wtedy ustawiamy je w conf/eth0/* . Natomiast
# opcje w conf/all/* odnoszą się do wszystkich interfejsów i zdefiniowane tam wartości są aplikowane
# w wyniku operacji OR/AND/MAX z tymi już ustawionymi, np. via conf/eth0/* . Zatem jeśli chcemy
# ustawić opcję log_martians=0 dla wszystkich interfejsów, wystarczy przełączyć default i all w
# stan 0. Jeśli zaś chcemy dodatkowo ustawić log_martians=1 tylko dla eth0, przestawiamy
# conf/eth0/log_martians na 1. W tym przypadku dokonaliśmy operacji OR między all i eth0 (0 or 1),
# co daje 1, przynajmniej dla tego interfejsu, z tym, że nie zawsze musi to być operacja OR.
#
# Poniżej znajduje się lista parametrów i odpowiadających im operacji:
#
#	       Parametr   |Operacja|                     Info
#   ------------------+--------+--------------------------------------------------------------------
#	accept_local         ?
#	accept_redirects     AND   oba z conf/{all,interface}/accept_redirects mają wartość 1
#	accept_source_route  AND   oba z conf/{all,interface}/accept_source_route mają wartość 1
#	arp_accept           ?
#	arp_announce         MAX   brana pod uwagę najwyższa wartość z conf/{all,interface}/arp_announce
#	arp_filter           OR    co najmniej jeden z conf/{all,interface}/arp_filter ma wartość 1
#	arp_ignore           MAX   brana pod uwagę najwyższa wartośc z conf/{all,interface}/arp_ignore
#	arp_notify           ?
#	bootp_relay          AND   oba z conf/{all,interface}/bootp_relay mają wartość 1
#	disable_policy       ?
#	disable_xfrm         ?
#	force_igmp_version   ?
#	forwarding           ?
#	igmpv2_unsolicited_report_interval  ?
#   igmpv3_unsolicited_report_interval  ?
#	log_martians         OR    co najmniej jeden z conf/{all,interface}/log_martians ma wartość 1
#	mc_forwarding        AND   oba z conf/{all,interface}/mc_forwarding mają wartość 1
#	medium_id            ?
#	promote_secondaries  ?
#	proxy_arp            OR    co najmniej jeden z conf/{all,interface}/proxy_arp ma wartość 1
#	proxy_arp_pvlan      ?
#	route_localnet       ?
#	rp_filter            MAX   brana pod uwagę najwyższa wartość z conf/{all,interface}/rp_filter
#	secure_redirects     OR    co najmniej jeden z conf/{all,interface}/secure_redirects ma wartość 1
#	send_redirects       OR    co najmniej jeden z conf/{all,interface}/send_redirects ma wartość 1
#	shared_media         OR    co najmniej jeden z conf/{all,interface}/shared_media ma wartość 1
#	src_valid_mark       ?
#	tag                  ?
#	disable_ipv6         ?
#
# Poniższy parametr odrzuca (wartość "0") source routowane pakiety. W przypadku konfiguracji routera
# należy ustawić ten parametr na "1". W każdym innym przypadku lepiej jest wyłączyć tę
# opcję -- włamywacze mogą używać tego typu pakietów do stworzenia pozorów, że ruch pochodzący od
# nich, tak naprawdę pochodzi z wnętrza sieci, a faktycznie będzie routowany z powrotem do ich
# maszyny. Source routingu bardzo rzadko używa się do legalnych czynności, więc można go bezpiecznie
# wyłączyć.
net.ipv4.conf.all.accept_source_route = 0
net.ipv4.conf.default.accept_source_route = 0
net.ipv6.conf.all.accept_source_route = 0
net.ipv6.conf.default.accept_source_route = 0
#
# Poniższy parametr odrzuca (wartość "0") przeadresowane pakiety ICMP, które mogą być używane do
# zmiany tablic routingu, co zwykle źle się kończy. (chroni przed atakami MITM).
# -- https://www.agwa.name/blog/post/icmp_redirect_attacks_in_the_wild
net.ipv4.conf.all.accept_redirects = 0
net.ipv4.conf.default.accept_redirects = 0
net.ipv6.conf.all.accept_redirects = 0
net.ipv6.conf.default.accept_redirects = 0
#
# Poniższy parametr akceptuje przekierowania ICMP tylko dla domyślnych bramek wymienionych w
# tablicy routingu. Można je podejrzeć przez ip route show .
net.ipv4.conf.all.secure_redirects = 1
net.ipv4.conf.default.secure_redirects = 1
#
# Poniższy parametr wyłącza przesyłanie pakietów ICMP redirect (typ 5). Mechanizm ICMP Redirect
# polega na przesyłaniu informacji o routingu przez routery do hostów docelowych. Informacja taka
# zawiera wiadomość o potencjalnie lepszej drodze dla pakietów, z której host powinien skorzystać,
# np. jeśli jakaś maszyna przesyła pakiety do routera R1, a ten przesyła je do routera R2, to w
# przypadku gdy ścieżka do routera R2 jest dostępna dla tego hosta (host i router R2 są w tym samym
# segmencie sieci), router R1 prześle pakiet ICMP Redirect do hosta z informacją, że ten ma słać
# pakiety przez router R2, a nie przez R1. Niesie to też za sobą problemy z bezpieczeństwem, bo taki
# pakiet można bez problemu spreparować. W przypadku gdy dany host nie jest routerem należy ten
# parametr ustawić na 0.
net.ipv4.conf.all.send_redirects = 0
net.ipv4.conf.default.send_redirects = 0
#
# Włącza filtrowanie trasy powrotnej pakietu. Gdy maszyna, która ma włączoną opcję filtrowania trasy
# powrotnej, otrzymuje pakiet, próbuje pierw sprawdzić czy źródło tego pakietu jest osiągalne przez
# interfejs, przez który pakiet trafił do danej maszyny. Jeśli źródło nie jest osiągalne, pakiety
# zostaną zrzucone. Znacznie poprawia to bezpieczeństwo ponieważ poważnie utrudnia spoofowanie
# adresu IP. W niektórych linuxach ten parametr przyjąć może wartości "0", "1" lub "2". W przypadku
# ustawienia "2", nie będzie miał znaczenia interfejs, przez który pakiet dodarł do maszyny, tylko
# to czy źródło pakietu jest osiągalne przez którykolwiek z nich. Trzeba przy tym pamiętać, że
# wyłączenie filtrowania trasy powrotnej może stwarzać problemy jeśli korzysta się z routingu
# asymetrycznego (pakiety od nas do komputera docelowego podróżują inną trasą niż te od niego do
# nas) lub jeśli pracuje się na nieroutoującym hoście posiadającym kilka adresów IP na różnych
# interfejsach, np. mając VPN.
net.ipv4.conf.all.rp_filter = 1
net.ipv4.conf.default.rp_filter = 1
#
# Pakiety "martian" to takie pakiety, których adres źródłowy lub docelowy wskazuje na jeden z
# adresów zarezerwowanych. Poniżej znajduje się lista takich adresów:
#
#   0.0.0.0/8           "This" network
#   10.0.0.0/8          Private-use networks
#   100.64.0.0/10       Carrier-grade NAT
#   127.0.0.0/8         Loopback
#   169.254.0.0/16      Link local
#   172.16.0.0/12       Private-use networks
#   192.0.0.0/24        IETF protocol assignments
#   192.0.2.0/24        TEST-NET-1
#   192.168.0.0/16      Private-use networks
#   198.18.0.0/15       Network interconnect device benchmark testing
#   198.51.100.0/24     TEST-NET-2
#   203.0.113.0/24      TEST-NET-3
#   224.0.0.0/4         Multicast
#   240.0.0.0/4         Reserved for future use
#   255.255.255.255/32  Limited broadcast
#
# Poniższy parametr ma na celu zalogowanie wszystkich pakietów, które nie powinny być widoczne w
# publicznym internecie, czyli tych co mają ustawiony jeden z powyższych adresów.
net.ipv4.conf.all.log_martians = 0
net.ipv4.conf.default.log_martians = 0
#
# Poniższy parametr wyłącza (wartość "1") obsługę protokołu IPv6 dla poszczególnych interfejsów.
net.ipv6.conf.all.disable_ipv6 = 0
net.ipv6.conf.default.disable_ipv6 = 0

# Włącza wsparcie dla dynamicznie zmieniających się adresów na interfejsach. Jest to bardzo
# przydatne w przypadku korzystania z interfejsu sprzęgniętego z linią telefoniczną, którego adres
# IP może się zmieniać. Jeśli nie jest się w posiadaniu stałego adresu IP, należy ustawić tutaj "1".
# W przypadku sprecyzowania wartości "2", kernel zaloguje zdarzenie zmiany adresu.
net.ipv4.ip_dynaddr = 0

# Połączenie TCP może znajdować się w jednym z następujących stanów:
# LISTEN        - gotowość do przyjęcia połączenia na określonym porcie przez serwer.
# SYN-SENT      - pierwsza faza nawiązywania połączenia przez klienta. Wysłano pakiet z flagą SYN.
#                 Oczekiwanie na pakiet SYN+ACK.
# SYN-RECEIVED  - otrzymano pakiet SYN, wysłano SYN+ACK. Trwa oczekiwanie na ACK. Połączenie jest w
#                 połowie otwarte (half-open).
# ESTABLISHED   - połączenie zostało prawidłowo nawiązane. Prawdopodobnie trwa transmisja danych.
# FIN-WAIT-1    - wysłano pakiet FIN. Dane wciąż mogą być odbierane ale wysyłanie jest już
#                 niemożliwe.
# FIN-WAIT-2    - otrzymano potwierdzenie własnego pakietu FIN. Oczekuje na przesłanie FIN od
#                 serwera.
# CLOSE-WAIT    - otrzymano pakiet FIN, wysłano ACK. Oczekiwanie na przesłanie własnego pakietu FIN
#                (gdy aplikacja skończy nadawanie).
# CLOSING       - jednoczesne obustronne zamknięcie połaczenia.
# LAST-ACK      - otrzymano i wysłano FIN. Trwa oczekiwanie na ostatni pakiet ACK.
# TIME-WAIT     - oczekiwanie w celu upewnienia się, że druga strona otrzymała potwierdzenie
#                 rozłączenia. Zgodnie z RFC 793 połączenie może być w stanie TIME-WAIT najdłużej
#                 przez 4 minuty.
# CLOSED        - połączenie jest zamknięte.
#
#                              +---------+ ---------\      active OPEN  
#                              |  CLOSED |            \    -----------  
#                              +---------+<---------\   \   create TCB  
#                                |     ^              \   \  snd SYN    
#                   passive OPEN |     |   CLOSE        \   \           
#                   ------------ |     | ----------       \   \         
#                    create TCB  |     | delete TCB         \   \       
#                                V     |                      \   \     
#                              +---------+            CLOSE     \   \   
#                              |  LISTEN |          ----------  |    |  
#                              +---------+          delete TCB  |    |  
#                   rcv SYN      |     |     SEND               |    |  
#                  -----------   |     |    -------             |    V  
# +---------+      snd SYN,ACK  /       \   snd SYN          +---------+
# |         |<-----------------           ------------------>|         |
# |   SYN   |                    rcv SYN                     |   SYN   |
# |   RCVD  |<-----------------------------------------------|   SENT  |
# |         |                    snd ACK                     |         |
# |         |------------------           -------------------|         |
# +---------+   rcv ACK of SYN  \       /  rcv SYN,ACK       +---------+
#   |           --------------   |     |   -----------                  
#   |                  x         |     |     snd ACK                    
#   |                            V     V                                
#   |  CLOSE                 +-------------+                              
#   | -------                | ESTABLISHED |                              
#   | snd FIN                +-------------+                              
#   |                   CLOSE    |     |    rcv FIN                     
#   V                  -------   |     |    -------                     
# +---------+          snd FIN  /       \   snd ACK          +---------+
# |  FIN    |<-----------------           ------------------>|  CLOSE  |
# | WAIT-1  |------------------                              |   WAIT  |
# +---------+          rcv FIN  \                            +---------+
#   | rcv ACK of FIN   -------   |                            CLOSE  |  
#   | --------------   snd ACK   |                           ------- |  
#   V        x                   V                           snd FIN V  
# +---------+                  +---------+                   +---------+
# |FINWAIT-2|                  | CLOSING |                   | LAST-ACK|
# +---------+                  +---------+                   +---------+
#   |                rcv ACK of FIN |                 rcv ACK of FIN |  
#   |  rcv FIN       -------------- |    Timeout=2MSL -------------- |  
#   |  -------              x       V    ------------        x       V  
#    \ snd ACK                 +---------+delete TCB         +---------+
#     ------------------------>|TIME WAIT|------------------>| CLOSED  |
#                              +---------+                   +---------+
#
# Przełączenie stanów charakterystyczne dla serwera:
# CLOSED > LISTEN > SYN-RECEIVED > ESTABLISHED > CLOSE-WAIT > LAST-ACK > CLOSED
#
# Przełączenie stanów charakterystyczne dla klienta:
# CLOSED > SYN-SENT > ESTABLISHED > FIN-WAIT-1 > FIN-WAIT-2 > TIME-WAIT > CLOSED
#
# Gniazda ze stanem TIME-WAIT mogą dotyczyć zarówno serwera jak i klienta, w zależności, która ze
# stron dokonała aktywnego zamknięcia połączenia, czyli będąc w stanie ESTABLISHED wyśle pakiet FIN
# na drugi koniec połączenia.
# http://www.isi.edu/touch/pubs/infocomm99/infocomm99-web/

# Pole numerów sekwencyjnych w protokole TCP ma tylko 32 bity, co ogranicza ich dostępną liczbę.
# W sieciach o dużej wydajności i transferze danych możliwe jest wyczerpanie się numerów
# sekwencyjnych przed przemierzeniem pakietu przez sieć. Jeśli dane przesyłane są w sieci z
# prędkością 1 Gbps, numery sekwencyjne mogą wyczerpać się w czasie od 17 do 34 sekund (w zależności
# od uzyskanej szybkości transferu). Jeśli z jakiegoś powodu jeden z pakietów został opóźniony
# potencjalnie możliwe jest, że inny pakiet będzie istniał z takim samym numerem sekwencyjnym i
# zostanie zaakceptowany jako bieżący. Wówczas może dojść do cichego zniszczenia danych (silent data
# corruption). Dlatego w celu uniknięcia nieporozumień podczas transmisji w przypadku powtarzających
# się numerów sekwencyjnych używa się znaczników czasu jako rozszerzenia tych numerów. W ten sposób
# pakiety posiadają postępujące (wzrastające) znaczniki czasu. Jeśli host wykryje, że timestamp
# segmentu jest mniejszy niż wartość ostatniego dobrego znacznika lub numer sekwencyjny jest większy
# niż ostatnie wysłane potwierdzenie, zostaje on odrzucony w transmisji.
#
# Niestety – dzięki opcji timestamp jesteśmy też w stanie bardzo prosto obliczyć uptime, czyli jak
# długo maszyna pracuje w sieci bez restartowania, a tym samym dowiedzieć się np. czy zostały na nią
# nałożone aktualizacje bezpieczeństwa wymagające restartu całego systemu. Patrząc na tą sytuację od
# strony komputera klienckiego – dzięki znacznikom czasu różne programy i urządzenia w internecie
# mogą odczytywać, obliczać i tworzyć indywidualne profile (służące do śledzenia aktywności) tzw.
# przesunięć czasowych impulsów zegarowych (clock skew) naszego komputera – w ten sposób nasza
# maszyna jest oznaczona "sprzętowo–programowym" ciasteczkiem już na poziomie warstwy transportowej,
# a nie aplikacji. Odczytanie wartości uptime przy użyciu nmap -- nmap -PN -O -v 10.10.10.10
# -- http://nfsec.pl/security/2306
net.ipv4.tcp_timestamps = 0
net.netfilter.nf_conntrack_timestamp = 0

# Czas przez który utrzymywać gniazdo w stanie FIN-WAIT-2 (oczekiwanie na ostatni pakiet FIN) jeśli
# zostało zamknięte przez drugą stronę. W przypadku gdy doszło do jakiejś awarii i tamten host
# zniknął z sieci, sesja może trwać w nieskończoność. Zbyt duża wartość może skutkować
# przeładowaniem pamięci martwymi gniazdami. Po upływie sprecyzowanego czasu, połączenie zostanie
# zakończone lokalnie. Gniazda w stanie FIN-WAIT-2 zajmują około 1.5 kB pamięci.
net.ipv4.tcp_fin_timeout = 20
net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 20
#
# Zaglądając do netstat można zauważyć, że połączenia w stanie TIME-WAIT praktycznie nie otrzymują
# żadnych danych, a mimo to, po zakończeniu właściwego połączenia, te gniazda utrzymują się jeszcze
# przez pewien czas, który zależy od ustawionego MSL (Maximum Segment Lifetime). Domyślnie jest to
# 30s. Zaś połączenie w stanie TIME-WAIT trwa 2 x MSL, czyli 60s. Ma to na celu przypisać zagubione
# pakiety do zamkniętego już połączenia. W przeciwnym wypadku, te pakiety mogłyby trafić do
# połączenia, które by zostało otwarte na tym samym gnieździe (ten sam protokół oraz te same adresy
# i porty źródłowe i docelowe), a to z kolei spowoduje uszkodzenie danych.
#
# Zbyt duża liczba połączeń może wyczerpać ilość dostępnych gniazd TCP i uniemożliwić tym samym
# nawiązywanie nowych połączeń. Jeśli mamy dużych rozmiarów serwer i kończą nam się gniazda, możemy
# ograniczyć ilość tych gniazd w stanie TIME-WAIT. Po przekroczeniu limitu, będą one zwyczajnie
# niszczone oraz zostanie zalogowane ostrzeżenie.
net.ipv4.tcp_max_tw_buckets = 4096
#
# RFC 1323 poprawia wydajność łącz o wysokiej przepustowości przez wprowadzenie szeregu dodatków,
# min. dwa czterobajtowe pola timestamp w opcjach TCP. Pierwsze z nich zawiera aktualną wartość
# znacznika czasu zegara podczas wysyłania pakietu, a drugie pole zawiera najnowszy znacznik czasu
# otrzymany od zdalnego hosta.
# http://vincent.bernat.im/en/blog/2014-tcp-time-wait-state-linux.html
#
# Przez włączenie tcp_tw_reuse, kernel użyje ponownie gniazda w stanie TIME-WAIT dla nowo
# utworzonego połączenia wychodzącego, tylko w przypadku gdy nowy znacznik czasu jest wyraźnie
# większy od ostatniego znacznika zarejestrowanego dla poprzedniego połączenia. Wykorzystanie
# ponownie gniazda w stanie TIME-WAIT będzie w takim przypadku możliwe po upłynięciu jedynie 1s.
net.ipv4.tcp_tw_reuse = 1
#
# Mechanizm tcp_tw_recycle jest podobny do tego opisanego powyżej ale dotyczy zarówno połączeń
# wychodzących jak i przychodzących. W przypadku połączeń przychodzących, ostatni znacznik czasu
# dla danego połączenia zostaje zapamiętany przy przechodzeniu tego połączenia w stan TIME-WAIT.
# Następnie, kernel zrzuci każdy segment od zdalnego hosta, którego znacznik czasu nie jest wyraźnie
# większy od tego zapamiętanego jako ostatni. W przeciwnym wypadku, gniazdo wygaśnie i będzie mogło
# zostać wykorzystane ponownie. W sytuacji gdy zdalny host jest urządzeniem NAT, ten mechanizm
# zezwoli tylko jednemu hostowi z tej sieci podłączyć się w czasie krótszym niż 1 minuta. Pozostałe
# będą musiały odczekać czas 2*MSL (60s), a to z tego powodu, że te maszyny nie dzielą tego samego
# zegara timestamp. Włączenie opcji tcp_tw_recycle może prowadzić do trudnych w wykryciu i
# zdiagnozowaniu problemów.
net.ipv4.tcp_tw_recycle = 0

# Maksymalna ilość śledzonych połączeń przez kernel, do wglądu w /proc/net/ip_conntrack lub
# /proc/net/nf_conntrack . W przypadku obciążonych serwerów może dojść do przepełnienia tej tablicy,
# co skutkuje zrzucaniem pakietów (DROP). Trzeba jednak rozważnie manipulować wartością poniższego
# parametru, bo każdy wpis w tej tablicy zajmuje około 350 bajtów, a dane pod te wpisy nigdy nie
# zostaną zrzucona do SWAP.
net.netfilter.nf_conntrack_max = 32032
#
# Ilość czasu (w sekundach), przez który połączenia w stanie ESTABLISHED niewysyłające lub
# nieodbierające danych będą śledzone przez kernel w tablicy conntracka. Po upływie tego czasu
# połączenie zniknie z tej tablicy ale powróci gdy jakieś dane zostaną znów przesłane. Pakiety
# keepalive odświeżają te wpisy, lecz nie wszystkie usługi mają ten ficzer zaimplementowany.
net.netfilter.nf_conntrack_tcp_timeout_established = 28800
#
# Ilość czasu (w sekundach), przez który połączenia w stanie TIME_WAIT są śledzone przez kernel.
# Obniżenie tego parametru rozładuje nieco tablicę conntracka w przypadku obciążonych serwerów, co
# złagodzi trochę apetyt na RAM.
net.netfilter.nf_conntrack_tcp_timeout_time_wait = 20
#
# Poniższy parametr ustawia timeout (w sekundach) dla pakietów ICMP w ruchu powrotnym (odpowiedź na
# zapytanie ICMP). W przypadku gdy został wysłany pakiet ICMP, z reguły oczekiwana jest odpowiedź na
# niego i jeśli nasze łącze nie należy do najlepszych jakościowo, powinniśmy ten parametr nieco
# podbić. W każdym innym przypadku można zostawić wartość domyślną (30) lub nawet nieco ją obniżyć.
net.netfilter.nf_conntrack_icmp_timeout = 30
net.netfilter.nf_conntrack_icmpv6_timeout = 30

# Ochrona przed atakami SYN flood . Atak ten polega na wysłaniu wielu pakietów z flagą SYN po czym
# nie udzielaniu odpowiedzi ACK na wysłane pakiety SYN-ACK serwera. W ten sposób na serwerze tworzy
# się wiele niezamkniętych sesji, które w końcu zapełnią całą wolną pamięć -- dane o każdym z
# klientów muszą być trzymane tak długo, aż w końcu się podłączy, czyli w nieskończoność. SYN flood
# skutecznie redukuje przepustowość łącza, lub też uniemożliwia innym osobom na podłączenie się do
# atakowanego serwera. Ten mechanizm zadziała dopiero w momencie gdy próg tcp_max_syn_backlog
# zostanie przekroczony.
# -- http://cr.yp.to/syncookies.html
net.ipv4.tcp_syncookies = 1
#
# Maksymalna ilość pamiętanych żądań połączeń, które nadal nie zostały potwierdzone przez klienta
# (stan HALF-OPEN). Minimalna wartość dla tego parametru to 128. Ten parametr jest ustawiany na
# starcie systemu w oparciu o ilość dostępnej pamięci RAM. Jeśli serwer cierpi z powodu
# przeładowania -- nawiązuje wiele set czy tysięcy połączeń w krótkim czasie -- dobrze jest
# zwiększyć tą wartość.
net.ipv4.tcp_max_syn_backlog = 128
#
# Poniższy parametr określa rozmiar kolejki nasłuchu (listen queue), czyli gniazd w stanie LISTEN .
# Jest to liczba jednoczesnych połączeń, które serwer stara się skonfigurować. Gdy połączenie
# zostanie ustanowione, nie występuje już w tej kolejce i ta liczba nie ma już większego znaczenia.
# Jeśli kolejka nasłuchu zostanie zapełniona w wyniku zbyt wielu jednoczesnych prób połączeń,
# kolejne próby będą zrzucane. Większe kolejki lepiej się sprawują w unikaniu ataków DoS.
net.core.somaxconn = 128

# Jeśli nie ma odpowiedzi na rozpoczynający połączenie pakiet SYN, kernel spróbuje ponowić zapytanie
# kilka razy i będzie robił to w ciągle zwiększających się odstępach czasu. Ustanawiając limit dla
# prób połączeń, można tym samym ograniczyć czas, przez który kernel będzie próbował ustanowić nowe
# połączenie. Przykładowo:
#
#     próby | czas na retransmisje (sekundy)
#    -------+--------------------------------
#       1   |   1
#       2   |   1+2=3
#       3   |   1+2+4=7 
#       4   |   1+2+4+8=15 
#       5   |   1+2+4+8+16=31 
#       6   |   1+2+4+8+16+32=63 
#       7   |   1+2+4+8+16+32+64=127 
#
# Wartość 4 oznacza zatem, że kernel, po nieudanej próbie nawiązania połączenia, spróbuje
# zretransmitować pakiet SYN 4 razy i jeśli żadna z tych prób się nie powiedzie, po czasie 15 sekund
# kernel odpuści.
net.ipv4.tcp_syn_retries = 4

# Gdy serwer otrzymuje zapytanie SYN, natychmiast wysyła odpowiedź w postaci pakietu z ustawionymi
# flagami SYN i ACK umieszczając jednocześnie to połączenie w kolejce (backlog queue) do chwili aż
# nadejdzie od klienta pakiet z ustawioną flagą ACK . Gdy taki pakiet nie nadchodzi, serwer
# retransmituje swój pakiet SYN-ACK kilka razy, dając tym samym szanse klientowi by spróbował
# odesłać pakiet ACK jeszcze raz. Jeśli adres klienta został zespoofowany, taka odpowiedź nigdy nie
# nadejdzie i serwer usunie to półotwarte połączenie. Połączenia w stanie SYN RCVD zajmują cenne
# zasoby i by odciążyć trochę maszynę można przyśpieszyć proces zamykania tego typu połączeń przez
# zmianę ilości retransmisji (działa na takiej samej zasadzie co tcp_syn_retries). Obniżenie
# wartości tego parametru w przypadku słabych łącz może powodować problemy z połączeniem.
# -- http://www.symantec.com/connect/articles/hardening-tcpip-stack-syn-attacks
net.ipv4.tcp_synack_retries = 3

# Maksymalna ilość osieroconych połączeń. Osierocone połączenie to takie gniazdo, które nie jest
# powiązane z żadnym deskryptorem pliku ale samo gniazdo ciągle istnieje w pamięci i czeka aż
# protokół TCP z nim skończy. Każde takie połączenie może zjeść do 64KiB pamięci i tych danych nie
# da rady przenieść do SWAP. Jeśli wartość tego parametru zostanie przekroczona, wszystkie sieroty
# zostaną natychmiast zresetowane i kernel wyrzuci ostrzeżenie. Domyślna wartość zależy od ilości
# posiadanej pamięci RAM. Ilość sierot można sprawdzić przez  /proc/net/sockstat .
# -- http://kaivanov.blogspot.com/2013/01/troubleshooting-out-of-socket-memory.html
# -- http://blog.tsunanet.net/2011/03/out-of-socket-memory.html
net.ipv4.tcp_max_orphans = 16384
#
# Poniższy parametr określa ile razy próbować zabić osierocone połączenie, odpytując przy tym drugą
# stronę, zanim połączenie zostanie ubite lokalnie.
#net.ipv4.tcp_orphan_retries = 0

# Poniższy parametr określa zakres portów efemerycznych (można także spotkać się z określeniami
# typu "porty prywatne" lub "porty dynamiczne". Są to, generalnie rzecz biorąc, porty tymczasowe
# wykorzystywane przy nawiązywaniu nowych połączeń -- jak tylko połączenie ulegnie zakończeniu,
# taki port jest zwalniany i może zostać wykorzystany przy kolejnym połączeniu. Porty z zakresu
# 49152–65535 nie mogą zostać zarejestrowane przez IANA i mogą być wykorzystywane do tego celu.
# Ilość portów efemerycznych wpływa na ogólną ilość połączeń jakie może nawiązać serwer i jeśli
# domyślny zakres nie wystarcza, można go rozszerzyć, np. kernele linuxowe zwykle używają zakresu
# od 32768 do 61000.
net.ipv4.ip_local_port_range = 49152 65535

# Wartość TTL (Time To Live) pakietów powinna zawierać się w przedziale od 1 do 255 włącznie, jako,
# że pole od TTL w nagłówku IP ma tylko 8 bitów. Domyślnie ten parametr przyjmuje wartość 64. W
# przypadku, gdy od maszyny docelowej dzieli nasz host sporo hopów, można nieco zwiększyć wartość
# tego parametru. Za każdym razem gdy pakiet przechodzi przez router, firewall, komputer, czy inne
# urządzenia sieciowe, TTL jest zmniejszany o 1. Ustawienie zbyt dużej wartości może w pewnych
# sytuacjach doprowadzić do takiego stanu, że pakiet będzie się odbijał o routery przez dłuższy
# czas zjadając przy tym cenne zasoby łącza. Standardowo nie notuje się trasy większej niż 30 hopów.
net.ipv4.ip_default_ttl = 64

# Zezwala lokalnym procesom przypisanie adresów IP nieistniejących na żadnym urządzeniu w systemie.
# Może to być użyteczne w przypadku gdy jest potrzeba by jakiś konkretny program, np. apache, był
# w stanie nasłuchiwać na innym adresie IP. Może to być użyteczne, jeśli komputer jest podłączony do
# dynamicznego łącza, więc dobrze byłoby gdyby usługi mogły startować i bindować się do określonych
# adresów gdy łącze jest nieczynne. Ta opcja może zaburzyć działanie pewnych aplikacji.
net.ipv4.ip_nonlocal_bind = 1

# Stan wpisów w tablicy ARP można śledzić przez:
# ip -s neigh show
# Można tam zaobserwować hosty w jednym z poniższych stanów:
# REACHABLE - zanim wpis wygasł ale po tym jak host został odłączony od sieci.
# STALE     - upłynęło gc_stale_time sekund od ostaniego zweryfikowania wpisu.
# DELAY     - kernel wkrótce wyśle zapytanie ARP pod adres docelowy.
# PROBE     - kernel rozwiązuje adres dla wpisu -- wysyła zapytania w liczbie ucast_solicit
#             (domyślnie 3) na ostatni link widniejący w tablicy ARP w celu zweryfikowania
#             osiągalności tego adresu. Jeśli ten proces się nie powiedzie, zostanie wysłane
#             zapytanie do wszystkich hostów w sieci w liczbie mcast_solicit (domyślnie 3) przed
#             zmianą stanu cache w tablicy ARP.
# INCOMPLETE - wysłano pierwsze zapytanie ARP.
# FAILED    - wyszukanie adresu nie powiodło się po sprecyzowanej liczbie prób dla zapytań ARP
#            (mcast_solicit)
#
# Gdy host w sieci zostanie odnaleziony, stworzony wpis w tablicy ARP jest uznawany za poprawny
# przez przedział czasu, który oscyluje w granicach od base_reachable_time_ms/2 do
# 3*base_reachable_time_ms/2 . Ważność wpisu zostanie przedłużona jeśli z tego adresu będą
# dostarczane jakieś pakiety. Czas podany w milisekundach.
net.ipv4.neigh.default.base_reachable_time_ms = 86400000
net.ipv6.neigh.default.base_reachable_time_ms = 86400000
#              
# Sprawdzanie tablicy ARP pod kątem starych wpisów (stan STALE). Gdy host został uznany za stary,
# zostanie rozwiązany ponownie przed wysłaniem do niego jakichkolwiek danych. Czas podany w
# sekundach.
net.ipv4.neigh.default.gc_stale_time = 86400
net.ipv6.neigh.default.gc_stale_time = 86400
#
# Gdy host został odłączony od sieci, istnieje pewien okres czasu, podczas którego inne hosty w tej
# sieci mogą posiadać wpisy w cache w swoich tablicach ARP dla tego odłączonego hosta:
#
# thresh1 określa rozmiar tablicy dla większych sieci liczących do 4096 hostów.
# thresh2 to soft limit odpowiadający za przejście w tryb agresywny i czyszczenie tablicy ARP.
# thresh3 to hard limit ustanawiający próg, którego rozmiar tablicy ARP nie może przekroczyć.
net.ipv4.neigh.default.gc_thresh1 = 4096
net.ipv4.neigh.default.gc_thresh2 = 8192
net.ipv4.neigh.default.gc_thresh3 = 16384

# Gdy linuxowa maszyna ma na pokładzie kilka kart sieciowych i zostanie podłączona do sieci, może
# odpowiadać na zapytania ARP z obu interfejsów, mimo, iż zostało ono wysłane tylko na jeden z nich.
# Tego typu sytuacja określana jest mianem ARP flux. Jeśli posiadamy kilka kart czy interfejsów
# sieciowych, dobrze jest ustawić tutaj wartość "1".
net.ipv4.conf.all.arp_ignore = 1
net.ipv4.conf.default.arp_ignore = 1

# Gdy okaże się, że jakiś segment TCP został utracony, protokół TCP przyjmuje, że został on zgubiony
# wskutek tłoku na routerze i przystępuje do kontroli zatłoczenia, w wyniku czego tempo nadawania
# danych może radykalnie spaść. Jeśli obie komunikujące się ze sobą strony uaktywnią funkcję ECN
# (Explicit Congestion Notification), zatłoczone routery będą stosownie oznaczać pakiety przed
# przekazaniem ich dalej. Ta strona, która otrzyma oznakowany w ten sposób pakiet, zażąda obniżenia
# tempa transmisji od hosta, który wysyła dane, po to, aby rozładować tłok i zapobiec utracie
# segmentów. Możliwość wykrycia tłoku, zanim zdarzy się utrata pakietu, zwiększa ogólną
# przepustowość łącza pomiędzy komunikującymi się maszynami.
#
# ECN jest efektywne tylko w połączeniu z Active Queue Management (AQM), a to jakie korzyści zostaną
# osiągnięte zależy od zastosowanego AQM. Korzystanie z ECN może także obniżyć wydajności w mocno
# zatłoczonych sieciach gdzie użyty algorytm AMQ nie gubi żadnych pakietów. Dodatkowo obie strony
# oraz routery na trasie pakietów muszą wspierać ten mechanizm by kontrola zatłoczenia mogła
# zadziałać. Można sprecyzować tutaj "0", "1" lub "2". W przypadku ustawienia "2", kontrola
# zatłoczenia będzie mogła zostać aktywowana tylko w przypadku gdy druga strona o nią poprosi.
# Mogą także pojawić się nieprzewidziane problemy z połączeniem po aktywowaniu tej funkcji i w
# przypadku gdyby wystąpiły, ten ficzer trzeba wyłączyć.
net.ipv4.tcp_ecn = 0

# Pole od rozmiaru okna w nagłówku TCP ma długość 16 bitów, co daje maksymalny rozmiar okna 65,535
# bajtów. Można obejść to ograniczenie zwiększając maksymalny rozmiar okien TCP do 1,073,725,440
# bajtów, czyniąc tym samym większy próg dla danych, które mogą być przesyłane przez sieć bez
# konieczności wysłania pakietu potwierdzającego, co powoduje zwiększenie przepustowości łącza.
net.ipv4.tcp_window_scaling = 1

# Ilość stron pamięci (pages) przeznaczonych dla gniazd TCP/UDP. Takie gniazdo identyfikuje konkretne
# połączenie, w skład którego wchodzi lokalny adres, lokalny port, zdalny adres, zdalny port oraz
# protokół. By przeliczyć strony pamięci na faktyczną jej objętość, trzeba przemnożyć ilość stron
# przez rozmiar strony. Z kolei rozmiar strony można uzyskać porównując dwa parametry
# z /proc/meminfo oraz /proc/vmstat , przykładowo:
#
#	$ cat /proc/meminfo | egrep -i "Mapped" && cat /proc/vmstat | egrep -i "nr_mapped"
#	Mapped:   67408 kB
#	nr_mapped 16852
#
# Rozmiar strony to  Mapped/nr_mapped , czyli 67408KiB/16852=4KiB albo 4096 bajtów. Poniższe 3
# wartości określają minimalną, umiarkowaną i maksymalną ilość stron pamięci, które mogą wykorzystać
# wszystkie gniazda TCP łącznie i odpowiadają odpowiednio za 64MiB, 96MiB i 144MiB pamięci. Ten
# parametr domyślnie jest kalkulowany przy starcie systemu w oparciu o ilość dostępnej pamięci RAM. 
net.ipv4.tcp_mem = 16500 24750 37125
net.ipv4.udp_mem = 16500 24750 37125

# Optymalny rozmiar buforów zależy od prędkości łącza oraz opóźnień (RTT) z jakimi dostarczane są
# pakiety. Dla przykładu, dla łącz 40Mbit/s o pingu 20 ms, optymalny rozmiar dla bufora to 209,715
# bajtów (2 x BDP). BDP to Bandwidth Delay Product i wylicza się go mnożąc prędkość przez czas
# opóźnień. W tym przypadku: 40 Mbps to 5,242,880 bajtów/s, a 20ms to 0,02/s. Po wymnożeniu tych
# dwóch wartości przez siebie dostajemy BDP 104,857. Bufor o rozmiarze 2 x BDP ma na celu
# zredukowanie opóźnienia z jakim wiąże się przesłanie pakietu potwierdzającego odebranie danych
# (ACK) -- w czasie czekania na potwierdzenie może zostać wysłana kolejna porcja danych. Dobrze jest
# ustawić maksymalny rozmiar bufora 3-4 krotnie większy, by pakiety z większymi opóźnieniami mogły
# podróżować z większą prędkością po kablach.
#
# Domyślne ustawienia dla wielkości wysyłanego (wmem) i odbieranego (rmem) bufora (w bajtach) dla
# wszystkich protokołów.
net.core.rmem_default = 327680
net.core.rmem_max = 327680
net.core.wmem_default = 327680
net.core.wmem_max = 327680
#
# Minimalny, domyślny i maksymalny rozmiar (w bajtach) otrzymanego (rmem) i wysłanego (wmem) bufora
# używanego przez gniazda TCP. Druga wartość poniższych parametrów nadpisuje net.core.rmem_default
# oraz net.core.wmem_default . W przypadku gdy system ma dostatecznie dużo pamięci sprecyzowanej w
# ipv4.tcp_mem , przydziela każdemu nowo utworzonemu gniazdu z automatu tyle RAMu ile widnieje na
# drugiej pozycji. Jeśli istnieje potrzeba, np. w przypadku szybkiego transferu danych czy większych
# opóźnień, kernel może zwiększyć limit dla takiego połączenia ale nie może on przekroczyć wartości
# maksymalnej. W przypadku gdy pamięć będzie na wyczerpaniu, połączenia już utworzone będą musiały
# się podzielić pamięcią z nowo tworzonymi gniazdami -- w przypadku tych połączeń, zostanie
# ograniczony transfer poprzez zmniejszenie bufora.
net.ipv4.tcp_wmem = 4096 81920 327680
net.ipv4.tcp_rmem = 4096 81920 327680
#
# Automatyczne dostrajanie wielkości otrzymanego bufora i co za tym idzie również okna TCP dla
# każdego połączenia. Maksymalna wartość bufora nie może przekroczyć tego zdefiniowanego w tcp_rmem.
net.ipv4.tcp_moderate_rcvbuf = 1

# Po ustanowieniu połączenia, systemy na dwóch jego krańcach próbują zwiększyć rozmiar okna TCP,
# tak by dane były przesyłane z prędkością obsługiwaną przez co najmniej jedną ze stron połączenia.
# Następnie połączenie przechodzi w fazę wykładniczego wzrostu (exponential growth). Rozmiar okna
# TCP jest zwiększany z każdym otrzymanym pakietem ACK o liczbę zaakceptowanych segmentów
# (dwukrotnie co kolejny RTT). Trwa to do chwili gdy jakieś potwierdzenie nie zostanie dostarczone
# lub gdy zostanie osiągnięty próg wielkość okna TCP. Po osiągnięciu progu, połączenie przechodzi
# w fazę liniowego wzrostu (linear growth), podczas której wielkość okna jest zwiększana o rozmiar
# jednego segmentu z każdym RTT i trwa to do momentu utraty potwierdzenia. Cały ten proces od
# ustanowienia połączenia do końca drugiej fazy nazywa się wolnym startem. Kluczowym jego elementem
# jest CWND (Congestion Window Size) -- jest to ilość segmentów składających się na początkowe okno
# TCP i domyślnie ten parametr jest ustawiony na 4*MSS lub 10*MSS (Maximum Segment Size). Wraz ze
# wzrostem przepustowości łącz oraz przez to, że połączenia są zwykle krótsze niż kiedyś, sporo z
# nich nigdy nie rozwija pełnej prędkości, właśnie ze względu na procedurę wolnego startu. Pociąga
# to za sobą także zwiększenie opóźnień.
# -- https://lwn.net/Articles/427104/
#
# Ilość początkowych segmentów w oknie TCP można zmienić przez:
#
#   # ip route change default via 10.1.255.253 dev eth0 initcwnd 16 initrwnd 16
#
# Jeśli chodzi o wolny start, trzeba też mieć na uwadze połączenia w stanie IDLE -- to takie,
# których sesja jest aktywna ale przez dłuższy okres czasu nie zostały przesłane żadne dane, np.
# połączenia SSL. Gdy dochodzi do ponownej transmisji danych, trzeba na nowo ustalić rozmiar okna
# dla tych danych, czyli połączenie znowu przechodzi w stan wolnego startu. W przypadku wyłączenia
# wolnego startu dla połączeń w stanie IDLE, po wznowieniu transmisji, dane będą przesyłane w oknach
# o rozmiarach ustalonych wcześniej, zanim połączenie weszło stan IDLE.
net.ipv4.tcp_slow_start_after_idle = 0
#
# Połączenia w stanie IDLE mogą zostać uszkodzone tworząc tym samym połączenia zombie i by jakoś
# sobie z nimi radzić stworzono mechanizm zwany keepalive, który polega na wysyłaniu pustych
# segmentów (niezawierających żadnych danych). Jeśli połączenie działa, druga strona odpowie
# pakietem ACK, a jeśli połączenie jest martwe, zostanie zresetowane pakietem RST.
# -- http://www.tcpipguide.com/free/t_TCPConnectionManagementandProblemHandlingtheConnec.htm
#
# Dwa pierwsze parametry są wyrażone w sekundach, ostatni zaś to zwykła liczba. Poniższe ustawienie
# wyśle pierwszy pakiet keepalive po 5min (300s), kolejne zaś będą wysyłane w odstępach 60s. Jeśli
# nie zostanie przesłany pakiet ACK po 3 próbach pod rząd, to po czasie 3*60s połączenie zostanie
# oznaczone jako uszkodzone i zostanie zresetowane.
net.ipv4.tcp_keepalive_time = 300
net.ipv4.tcp_keepalive_intvl = 60
net.ipv4.tcp_keepalive_probes = 3

# W przypadku ustawienia na "0", dane dotyczące połączeń zostaną zapisane w celu optymalizacji
# sieci. Może to jednak doprowadzić do utraty wydajności ponieważ protokół TCP zastosuje wyjątek dla
# każdego nowego połączenia, które zostanie ustanowione w przeciągu kilku następnych minut. Innymi
# słowy, w pewnych przypadkach jeśli jakaś osoba przegląda strony na takim serwerze i ma losowe
# utraty pakietów, może doświadczyć gorszej wydajności serwera nawet w przypadku gdy problemy
# znikną. Jeśli w grę wchodzi ruchu z urządzeń mobilnych lub słabych jakościowo połączeń, dobrze
# jest ustawić tutaj "1".
net.ipv4.tcp_no_metrics_save = 0

# Path MTU Discovery decyduje o tym, czy połączenie TCP ma korzystać ze stałej, maksymalnej
# wartości MTU, czy też ma próbować ją sobie samodzielnie ustalić. W tym celu stos IP ustawia w
# każdym wychodzącym pakiecie bit "Don't Fragment". Gdy nadejdzie odpowiedni komunikat statusu ICMP,
# wartość MTU jest zmieniana zgodnie z wiadomością. Standardowo Path MTU Discovery jest aktywny, a
# jego działanie można sprawdzić przez:
#
#   # tracepath -n 10.10.10.10
#
# Badanie MTU może się nie sprawdzać w przypadku źle skonfigurowanych firewalli, które odrzucają
# wszelkie pakiety ICMP lub też w przypadku źle skonfigurowanych interfejsów, np. gdy oba końce
# połączenia point-to-point nie zgadzają się na MTU. 
net.ipv4.ip_no_pmtu_disc = 0

# Chroni przez atakiem TCP TIME-WAIT Assassination . Zakłada on wykorzystanie gniazd w stanie
# TIME-WAIT serwera przez klienta podczas ponownego połączenia się w czasie nieprzekraczającym
# 2*MSL, czyli żywotności takiego gniazda. Serwer może zareagować na taką sytuację w dwojaki
# sposób -- albo zrzuci zapytanie SYN i poczeka na wygaśnięcie gniazda, albo zaakceptuje pakiet SYN
# i gniazdo przejdzie ze stanu TIME-WAIT w stan ESTABLISHED. Aktywowanie tej opcji spowoduje, że
# kernel będzie odrzucał pakiety RST dla gniazd w stanie TIME-WAIT. Dodatkowo, po jej włączeniu,
# mogą wystąpić spore problemy w sieci p2p.
# -- http://blogs.technet.com/b/networking/archive/2010/08/11/how-tcp-time-wait-assassination-works.aspx
net.ipv4.tcp_rfc1337 = 0

# Liczba przychodzących pakietów, które mogą zostać zakolejkowane na interfejsach w przypadku gdy
# kernel wolniej przetwarza dane niż one napływają. Jeśli kolejka jest zbyt krótka, owocować to
# będzie zrzucaniem pakietów (DROP). Każdy rdzeń ma swoją własną kolejkę. 
net.core.netdev_max_backlog = 2500

# Jeśli jakiś host wysłał 10,000 bajtów i bajty 3000-5000 zostały utracone podczas przesyłu, pakiet
# ACK poinformuje, że odbiorca otrzymał tylko dane od 0-2999 bajtów. W takim przypadku, maszyna
# wysyłająca dane musi przesłać bajty od 3000-10000. Z kolei SACK może powiedzieć, że odbiorca
# otrzymał bajty od 0-2999 oraz 5001-10000, czyli, że zgubiono bajty od 3000-5000 i wymagane będzie
# przesłanie tylko tego brakującego kawałka, co poprawi ogólną wydajność przesyłu, jednak są
# potrzebne dodatkowe zasoby procesora i pamięci w porównaniu do zwykłego mechanizmu ACK. W pewnych
# warunkach jednak, mogą pojawić się też problemy z wydajnością serwera -- atakujący może zmusić
# maszynę do trzymania sporej kolejki na retransmisje pakietów przez długi czas, co może zjeść
# procesor, pamięć RAM oraz więcej łącza niż w rzeczywistości powinno. Jeśli serwer jest solidny i
# nie przesyła dużych plików, tego typu sytuacja mu nie zagraża. W przypadku gdy serwer ma na celu
# dbanie o jak najniższe opóźnienia, SACK jest zbędny i może stanowić zagrożenie dla bezpieczeństwa
# maszyny. W przypadku słabych i wolnych łącz, SACK może powodować problemy przez nasycenie łącza
# pakietami ACK i powinien zostać wyłączony.
# -- http://packetlife.net/blog/2010/jun/17/tcp-selective-acknowledgments-sack/
net.ipv4.tcp_sack = 1
#
# Zezwala na wysyłanie zduplikowanych pakietów SACK.
net.ipv4.tcp_dsack = 1
# 
# Włącza opcje unikania zatorów i szybkich retransmisji pakietów. W przypadku ustawienia tcp_sack na
# "0", ten parametr jest ignorowany.
net.ipv4.tcp_fack = 1

# Aktywuje TCP Fast Open, co ma na celu wyeliminowanie początkowego RTT przy nawiązywaniu
# połączenia podczas three-way handshake i tym samym zmniejszenie opóźnień, bo część pakietu SYN
# będzie zawierać faktyczne dane. Może to poprawić wydajność łącza nawet o 40% przy przeglądaniu
# stron www. Jednak system ten opiera się o generowane ciasteczka weryfikujące tożsamość klienta, a
# to niestety pociąga za sobą lekkie utylizowanie procesora. By ten mechanizm zadziałał, aplikacje
# również muszą mieć zaimplementowaną jego obsługę. Jeśli w poniższym parametrze zostanie ustawiona
# wartość "1", aplikacja będzie mogła żądać ciasteczek i tym samym wysyłać dane w pakietach
# inicjujących połączenie (SYN) ze stacji klienckich. Z kolei wartość "2" umożliwia serwerowi
# generowanie ciasteczek i akceptowanie tego typu żądań zanim three-way handshake zostanie
# ukończone. Wartość "3" włącza funkcjonalność zarówno serwera jak i klienta na danej maszynie.
# Istnieje także możliwość sprecyzowania wartości "4" i w takim wypadku dane mogą być przesyłane bez
# względu na dostępność ciasteczek.
# -- http://lwn.net/Articles/508865/
net.ipv4.tcp_fastopen = 1

# Narzędzie ptrace może zostać wykorzystane przez niepowołane osoby np. w celu debugowania procesu
# jako nieuprzywilejowany użytkownik, aby odczytać zawartość pamięci programu. Przed tego typu
# sytuacją może nas uchronić moduł Yama, który zawiera cały szereg zabezpieczeń typu DAC
# (Discretionary Access Control), czyli metod kontroli, w których prawo dostępu do wybranych
# obiektów jest wyznaczone na podstawie prawa własności obiektu, identyfikacji podmiotu próbującego
# uzyskać dostęp do danego zasobu oraz pośrednio lub bezpośrednio sformułowanych praw dostępu do
# zasobu przyznanych podmiotowi przez właściciela zasobu.
#
# W poniższym parametrze możemy sprecyzować cztery wartości:
#	0 – wszystkie procesy mogą być debugowane o ile posiadają ten sam uid (standardowa praca),
#	1 – tylko proces macierzysty może być debugowany,
#	2 – tylko administrator może używać ptrace (procesy muszą posiadać ustawione CAP_SYS_PTRACE),
#	3 – żaden proces nie może zostać śledzony za pomocą ptrace (wymaga restartu do przywrócenia
#	    innego trybu).
kernel.yama.ptrace_scope = 1

# Ustawianie opcji SO_SNDBUF w przypadku unixowych soketów datagramowych (Datagram Unix Domain
# Socket) może przynieść oczekiwane efekty ale już w przypadku opcji SO_RCVBUF nie za bardzo i nawet
# jeśli bufor jest spory, nadal możemy doświadczyć problemu z nadmiarem pakietów. A wszystko
# dlatego, że w stosunku do tego typu soketów istnieje inne ograniczenie jeśli chodzi o kolejkę
# w buforze, a ta z kolei nie jest nieskończona. W większości systemów linuxowych ta kolejka jest
# ustawiona na 10, co oznacza, że tylko 10 pakietów może czekać w kolejce i każdy nadmiarowy
# zostanie zrzucony.
net.unix.max_dgram_qlen = 256



#==============================

# Domyślne ustawienia rozmiaru tablicy hashy routingu są kalkulowane na starcie systemu w oparciu o ilość
# pamięci RAM. Rozmiarem tablicy można jednak manipulować przez dopisanie rhash_entries=1048576 do linijki
# kernela w extlinux/grub . Aktualny rozmiar tablicy można odczytać z logów kernela przez:
#
#	# dmesg | grep '^IP route' .
#
# Routing ma także swój cache, który jest czyszczony ramach procesu zwanego garbage collection. Polega on na
# przeskanowaniu oraz usunięciu martwych lub starych wpisów. Proces oczyszczania cache routingu może
# zainicjować kilka czynników, np. gdy maksymalny rozmiar cache zostanie przekroczony. Można także ustawić
# próg, po przekroczeniu którego cache będzie automatycznie czyszczony co pewien okres czasu. Każdy wpis w
# cache zajmuje 256 bajtów. Statystyki wykorzystania cache tablicy routingu można śledzić przez:
#
#	# lnstat -s1 -i1 -c-1 -f rt_cache
#
# -- http://vincent.bernat.im/en/blog/2011-ipv4-route-cache-linux.html
#
# Gdy liczba wpisów w cache przekroczy wartość rhash_entries*gc_elasticity , cache zaczyna być traktowany jako
# potencjalnie niebezpieczny i oczyszczanie będzie się dokonywać bardziej agresywnie.
#net.ipv4.route.gc_elasticity = 8
#net.ipv6.route.gc_elasticity = 9
#
# Maksymalna ilość wpisów w cache routingu -- ta wartość nie może zostać przekroczona.
#net.ipv4.route.max_size = 2147483647
#net.ipv6.route.max_size = 4096
#
# Minimalny interwał pomiędzy dwoma wybudzeniami oczyszczania, za wyjątkiem sytuacji gdy cache się zapełni.
#net.ipv4.route.gc_min_interval_ms = 500
#net.ipv6.route.gc_min_interval_ms = 500
#
# Gdy liczba wpisów przekroczy próg gc_thresh, nowe wpisy w cache routingu uruchomią oczyszczanie tablicy z
# częstotliwością sprecyzowaną w gc_min_interval_ms . Powinien mieć taką samą wartość co parametr
# rhash_entries .
#net.ipv4.route.gc_thresh = -1
#net.ipv6.route.gc_thresh = 1024
#
# Podobny do gc_min_interval_ms z tą różnicą, że w tym przypadku cache jest oczyszczany co pewien okres czasu
# i nie ma znaczenia przy tym parametr gc_thresh .
#net.ipv4.route.gc_interval = 60
#net.ipv6.route.gc_interval = 30
#
# Czas, po upłynięciu którego kernel oznaczy wpis w cache jako stary. Jeśli konfiguracja interfejsu została
# zmieniona, wpis zostaje usunięty. W innym przypadku kernel patrzy na wiek wpisu i jego pozycję w łańcuchu.
# Jeśli wpis jest pierwszy w łańcuchu, będzie ważny przez okres czasu określony w route.gc_timeout . Jeśli
# wpis znajduje się na drugiej pozycji, przez route.gc_timeout/2 , jeśli jest trzeciej, to przez
# route.gc_timeout/4 itd. Jeśli żaden wpis nie zostanie oznaczony jako stary w przypadku zainicjowania garbage
# collection, oczyszczanie śmieci zostanie uruchomione ponownie, z tym, że teraz będzie agresywniejsze -- tak
# gdyby route.gc_timeout został ustawiony na połowę sprecyzowanej wartości.
#net.ipv4.route.gc_timeout = 300
#net.ipv6.route.gc_timeout = 60
#
# Poniższe dwa parametry ograniczają ilość komunikatów ICMP destination unreachable generowanych przez kod
# routującu. Opcja error_burst określa maksymalną ilość tokenów, które mogą zostać przeznaczone na wszystkie
# komunikaty, zaś error_cost określa ile tokenów zostanie użytych przez każdy wysłany pakiet ICMP destination
# unreachable . Domyślne ustawienia ograniczają generowanie wiadomości do pięciu na jedną sekundę. Jeśli
# error_burst zostanie opróżniony, kolejne wiadomości zostaną zignorowane.
# -- http://rlworkman.net/howtos/ipsysctl/chunkyhtml/routereference.html
#net.ipv4.route.error_burst = 1250
#net.ipv4.route.error_cost = 250
#
#net.ipv4.route.min_adv_mss = 256
#net.ipv6.route.min_adv_mss = 1220
#
#net.ipv4.route.mtu_expires = 600
#net.ipv6.route.mtu_expires = 600
#
#net.ipv4.route.min_pmtu = 552
#net.ipv4.route.redirect_load = 5
#net.ipv4.route.redirect_number = 9
#net.ipv4.route.redirect_silence = 5120
